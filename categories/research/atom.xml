<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Research | Ourren]]></title>
  <link href="http://blog.ourren.com/blog/categories/research/atom.xml" rel="self"/>
  <link href="http://blog.ourren.com/blog/"/>
  <updated>2015-07-20T23:57:26-07:00</updated>
  <id>http://blog.ourren.com/blog/</id>
  <author>
    <name><![CDATA[ourren]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Measuring and Detecting Malware Downloads in Live Network Traffic]]></title>
    <link href="http://blog.ourren.com/blog/2015/07/03/measuring-and-detecting-malware-downloads-in-live-network-traffic/"/>
    <updated>2015-07-03T00:32:58-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/07/03/measuring-and-detecting-malware-downloads-in-live-network-traffic</id>
    <content type="html"><![CDATA[<p>今天分享的是Roberto Perdisci教授在2013年发表在ESORICS上的一篇论文，该文在Google学术中虽然引用不高，单独读完之后感觉在分类前提取特征的方法写得不错，分享给大家。</p>

<h3>概述</h3>

<p>论文主要观点：</p>

<p>通过在网络出口部署相关设备，可以观察局域网内所有软件下载行为，通过一系列的行为特征和恶意软件的标签即可实现恶意软件的分类，并且可以发现未知恶意软件，同时该分类效果比谷歌浏览器的恶意检测系统在一定程度上误报率要低。</p>

<p>论文主要成果：</p>

<ul>
<li>提出了一种在网络数据包中检测恶意软件下载行为的模型；</li>
<li>通过实际部署发现效果还不错，可以发现一些未知的恶意样本；</li>
<li>通过对比发现，模型的误报率其实挺低，准确率也挺高的。</li>
</ul>


<!--more-->


<h3>模型框图</h3>

<p><img src="http://blog.ourren.com/upload/amico.png" alt="amico" /></p>

<h3>创新技术点</h3>

<p>个人感觉论文主要的亮点在于对这种检测模型中的特征的挖掘和阐述，其次文章对模型和整个研究内容的细节和死角都做了很详细的分析和阐述，让你找不出破绽。另外作者的测试方法也还是蛮有意思的。</p>

<p>这里重点阐述作者模型中的特征选取问题：</p>

<h4>历史下载数据。</h4>

<p>通过分析连续一段时间文件的下载次数，多少客户下载，第一次下载是多少天以前，一天有多少下载量等，这个作为一个大类的特征，然后分为很多小特征。</p>

<p>「选择依据」一个正常软件的sha1值一般是固定的，因为一般软件升级需要一段时间，而恶意软件则需要经常免杀，所以sha1值经常变动，导致每个sha1值的下载量很少，并且恶意软件下载的量一般也会很少。</p>

<h4>域名特征</h4>

<p>主要涉及域名的二级域名，或者域名后缀，同时结合历史数据来计算每一类域名的恶意概率，正常文件对应的数量，每个顶级域名下载量等。</p>

<p>「选择依据」恶意软件虽然经常变换域名，但是很多时候可能只是更换二级域名或者是直接更换定于域名，但是一般情况下后缀不会改变，另外恶意域名对应的下载量应该很小，应该会经常变换域名和文件。</p>

<h4>服务端IP特征</h4>

<p>涉及服务端IP所属BGP，服务器地区，然后跟这几个属性关联的数量，比如某个BGP下下载量是多少，有多少正常文件等等。</p>

<p>「选择依据」恶意文件托管或者存放一般可能会改动IP地址，但是改动不大，可能还是一些BGP下，那么统计其分布情况和数量就非常重要。</p>

<h4>URL特征</h4>

<p>主要考虑URL的构成（路径，特殊符号，参数，文件名等）跟恶意数量和正常样本的数量分布情况，</p>

<p>「选择依据」考虑一个团伙或者一套恶意系统往往存在一些相似的地方，其URL相似度可能比较高。</p>

<h4>下载请求特征</h4>

<p>恶意软件下载的时候请求头，是否带有referer url，路径的深度等于历史。</p>

<p>「选择依据」很多恶意请求基本上referer都是为空，另外恶意文件下载的链接跟正常的一般也不一样，没有jpg,gif这些后缀。</p>

<h3>缺点</h3>

<ul>
<li>虽然作者考虑了很多因素来综合评定文件是否恶意，但是HTTPS没办法测试，除了SSLtrip。</li>
<li>针对分段的恶意木马没办法检测；</li>
<li>恶意攻击者可以针对性改进。</li>
</ul>


<p>后话，作者主页上的<a href="http://roberto.perdisci.com/useful-links">Useful Public Resources</a>对恶意库和检测平台总结还是比较全，推荐。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding and Monitoring Embedded Web Scripts]]></title>
    <link href="http://blog.ourren.com/blog/2015/06/18/understanding-and-monitoring-embedded-web-scripts/"/>
    <updated>2015-06-18T10:26:49-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/06/18/understanding-and-monitoring-embedded-web-scripts</id>
    <content type="html"><![CDATA[<p>该篇文章发表于36th IEEE Symposium on Security and Privacy (&ldquo;Oakland&rdquo;)「属于安全界的顶级会议」，而作者是Yuchen Zhou，毕业于University of Virginia，目前就职Palo Alto Networks。从作者的<a href="http://www.yuchenzhou.info/research">个人主页</a>可以看到其主要的研究内容：通过修改浏览器中特殊功能来实现对单点Web安全技术进行研究。PS：发的顶会文章也是够多的。</p>

<p>该<a href="http://scriptinspector.org/">项目</a>主要开发了一个修改版的Firefox浏览器「ScriptInspector」来帮助网站管理人员查看网站第三方JavaScript对网页内容的相关操作，主要分为三个模块：ScriptInspector，Visualizer和PolicyGenerator。</p>

<ul>
<li>ScriptInspector：基于Firefox的修改版浏览器，主要修改window.eval等函数的hook. 用来记录第三方脚本的函数调用，主要包含：DOM, 本地存储和网络。</li>
<li>Visualizer：一个Firefox插件，用来高亮显示页面中被访问的节点，可以快速了解第三方脚本的操作。</li>
<li>PolicyGenerator：用于辅助人员生成各种第三方脚本的访问策略，通过这些脚本在不同网站的访问情况可以推断该脚本的安全性。</li>
</ul>


<!--more-->


<p>作者通过分析把第三方脚本的操作分为了如下大类：获取浏览器版本，网络请求，修改网页内容，读取网页内容，记录用户操作，脚本插入，获取属性值。在具体实现部分从技术上讲解了这几类操作的实现细节。</p>

<p>在策略分类问题上，主要分为几下几类：统计分析类脚本，广告类脚本，社交类脚本和Web开发类脚本「比如Jquery,google font等」。</p>

<p>在最终测试中发现了很多有意思的东西：Alex 200的网站嵌入第三方脚本很多，并且有些脚本有违规的操作，比如每个网站平均需要6个权限，Facebook和Twitter请求权限很多，并且有时候会读取其它网页内容或者操作行为等，详细可以参考论文的「POLICY EVALUATION」。</p>

<p>相关研究中对客户端脚本安全进行了详细的梳理，可以说非常不错。</p>

<h3>点评</h3>

<p>其实研究第三方脚本的安全隐私的论文已经很多了「可以参考文章中得相关工作和参考文献」，但是一般情况都是直接写一个插件利用JS HOOK来记录脚本的活动「Ghostery，BEEP，MashupOS，OMash」，而基于修改版的Firefox则很少，工业界中<a href="https://dominator.mindedsecurity.com/">DOMinator</a>利用修改版的Firefox来挖掘DOM XSS，而学术界貌似很少。 其实CSP的提出也是用于解决此类安全问题。</p>

<p>另外论文的工作量看起来是比较多的，但是说实话测试数据不是很大，下载使用其程序感觉不够稳定，基本上算demo版本。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Detecting Spammers on Twitter]]></title>
    <link href="http://blog.ourren.com/blog/2015/05/21/detecting-spammers-on-twitter/"/>
    <updated>2015-05-21T19:43:11-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/05/21/detecting-spammers-on-twitter</id>
    <content type="html"><![CDATA[<p>文章主要是通过机器学习的思路来自对twitter的用户进行分类「两类：正常用户与垃圾用户」。其中算法采用的是SVM算法，特征选取比较复杂，结合了内容特征与用户行为特征。个人感觉不错的是论文针对特征的选取和特征的精简部分。</p>

<h3>整体流程</h3>

<ol>
<li>首先爬取了大量Twitter用户的数据（通过API接口 + 大量VPS/IP）；</li>
<li>通过特定主题进行跟踪，例如跟踪：「the Michael Jackson’s death」，「Susan Boyle’s emergence,」，「the hashtag “#musicmon- day”」；即把这几个主题的发言和评论抓出来进行分析；这里实验数据处理的时候有一个技巧：正常内容很多，而垃圾内容太少，为了不让比例失调，特别减少了正常用户的比例，基本上「正常用户:垃圾用户(1：2)」;</li>
<li>手动做标签，作者写分为三个人同时对同一样本做标签，然后标识的时候需要参照三个人的答案；</li>
<li>提取特征值，鉴于特征值比较多，因此需要针对特征值进行分析，分析单一特征是否可以区分两类用户；</li>
<li>通过SVM算法对已经标识的样本进行建模，然后测试样本；</li>
<li>通过分析特征值，降维处理「减少特征值」；</li>
<li>最后计算准确率并分析。</li>
</ol>


<!--more-->


<h3>创新点</h3>

<ol>
<li>从内容特征和用户特征对twitter社交数据进行特征提取，内容特征考虑：最大长度，最小长度，均值，一个内容中的主题(##), 网址数量，单词数量，数字出现个数，@的用户数量，有多少人转发等「39个属性」；用户特征：粉丝数量，关注数量，发帖数量，转帖数量，年龄，被@多少次，多少次回复，发帖时间间隔，一天发多少帖，一周发多少帖「23个属性」。</li>
<li>单一特征对分类的影响采用了cumulative distribution function (CDF)进行了分析，不熟悉CDF的可以看这里<a href="http://www.lifelaf.com/blog/?p=746">一维数据可视化：累积分布函数(Cumulative Distribution Function)</a>;</li>
<li>SVM分类中采用了5阶交叉验证，即SVM参数的不同；</li>
<li>通过信息增益或者X2统计分析TOP10,TOP20,-TOP50特征值「内容特征与用户特征」的数量；关于信息增益可以看这里：<a href="http://www.blogjava.net/zhenandaci/archive/2009/03/24/261701.html">文本分类入门（十一）特征选择方法之信息增益</a>;</li>
<li>然后用这些特征再次测试准确率。</li>
</ol>


<h3>总结</h3>

<p>从工作量上看确实需要做大量的工作，另外作者对特征选取，特征优化这些做得很不错。最后请记住这个是2010年的论文。</p>

<p>论文下载<a href="http://www.decom.ufop.br/fabricio/download/ceas10.pdf">Detecting Spammers on Twitter</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On the Relations Between the Different Actors in the Spam Landscape]]></title>
    <link href="http://blog.ourren.com/blog/2015/05/11/on-the-relations-between-the-different-actors-in-the-spam-landscape/"/>
    <updated>2015-05-11T17:42:36-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/05/11/on-the-relations-between-the-different-actors-in-the-spam-landscape</id>
    <content type="html"><![CDATA[<p>该篇论文的题目为：<a href="http://dl.acm.org/citation.cfm?id=2590302">The Harvester, the Botmaster, and the Spammer- On the Relations Between the Different Actors in the Spam Landscape</a> 通过分析Harvester，Botmaster和Spammer之间的关系。</p>

<p>其实整个过程可以描述为：攻击者从网络上收集邮箱地址，然后利用Botnet发送推广广告或者恶意内容，从而获利。因此论文中对整个过程进行了重现：</p>

<ul>
<li>自己搭建了网络服务并把邮件地址公布在网络上「采用的是自己搭建的邮件服务器」，等待攻击者来采集邮箱，同时记录下其爬虫的标示「HTTP头，IP地址和其它信息」；</li>
<li>记录邮件服务器软件的收信过程，详细记录投递过程，攻击者在发送邮件的时候会暴露一些特征「使用邮件服务器，握手过程」；</li>
<li>对攻击者发送的内容进行分析「主题，域名，发送软件，发件人」；</li>
<li>通过以上数据对这个攻击链进行分析。</li>
</ul>


<!--more-->


<h3>贡献</h3>

<p>通过阅读论文，发现文章主要有如下的贡献点：</p>

<ul>
<li>通过搭建蜜罐系统来分析这个攻击链，可以说工作量相对比较多，思路也不错；</li>
<li>提出了SMTP通信痕迹概念，其实这个概念作者以前的文章就提出了。按照我的理解就是如果使用自定义搭建的SMTP发信的时候通信过程中会多一些步骤，同时可以通过这个过程来标示一个发信机器；</li>
<li>从邮件内容对恶意攻击进行分类，根据内容分为不同的列别；同时通过了Anubis和virustotal来分析IP的历史数据，是否存在恶意行为；</li>
</ul>


<h3>缺点</h3>

<p>但是个人感觉文章存在以下不足：</p>

<ul>
<li>观测时间太短，从2012.12.14-2013.05.15时间跨度太短，做的网站很可能Google都还没有被收录，攻击者就没有办法获取你的邮箱地址；同时可以发现后面的发件人IP居然只有75个，不得不说数据量确实很少；</li>
<li>还是上面的问题，始终感觉这种方式去逼近地下产业，数据量和切入点都太小了。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On the Arms Race in Spamming Botnet Mitigation]]></title>
    <link href="http://blog.ourren.com/blog/2015/05/08/on-the-arms-race-in-spamming-botnet-mitigation/"/>
    <updated>2015-05-08T14:54:59-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/05/08/on-the-arms-race-in-spamming-botnet-mitigation</id>
    <content type="html"><![CDATA[<p>此文档是G Stringhini的开题报告<a href="http://www0.cs.ucl.ac.uk/staff/G.Stringhini/papers/writeup.pdf">这里下载</a>,针对Botnet的技术进化和科研上对应的防御方案进行了详细地讨论，对于研究botnet的人来说是一份非常不错得入门资料。文档主要分为四个部分:</p>

<ul>
<li>引言简单介绍了Botnet的威胁，来源和发展；</li>
<li>第二部分主要介绍Botnet的进化，包含Botnet的通讯架构和感染两部分；</li>
<li>第三部分主要介绍科研上针对Botnet和垃圾邮件的检测和防御机制；</li>
</ul>


<!--more-->


<h3>引言</h3>

<p>垃圾邮件可以被用来钓鱼，诈骗，但是很多大型电子商务网站都提供推荐/推广功能，攻击者可以通过发送大量这种邮件这种进行获利，然而你这类邮件基本上都是从Botnet机器进行发送，并且调查发现85%的Botnet机器都被用来发送垃圾邮件。针对这种现状研究人员和攻击者一直在这个技术领域进行较量。</p>

<h3>Botnet的进化</h3>

<p>Botnet架构的进化流程如下。</p>

<ul>
<li>IRC Botnet: 最初的Botnet是基于IRC的，受害者通过IRC地址和密码进入特定频道等待管理员发布命令。这种通信方式的弱点：研究人员可以通过恶意文件分析IP地址和密码，然后进入频道分析其行为；另外如果IRC基于域名，研究人员可以通过DNS重定向将所有的受害者机器进行转移；最后IRC协议明文通讯，可以通过协议上对这种行为进行检测；</li>
<li>专有协议Botnet：为了避免已有的协议，攻击者通过自定义加密协议来进行通信；缺点在于研究人员可以对样本进行逆向分析其协议，并可以加入其队列分析行为；另外也存在DNS污染攻击；</li>
<li>多级代理Botnet：通过多次跳转/代理进行隐藏，这种方式还是可以通过黑名单进行block;</li>
<li>域名生成算法Botnet：通过设计一套基于时间的域名生成算法(DGA)，来实现不同时间段的回连地址; 算法部分也可以通过社交网络的标题或者内容进行回连。缺点在于攻击者可以逆向算法并提前注册域名或者攻击社交账号，或者直接block这些域名；</li>
<li>P2P Botnet：针对无公网IP地址的内部受害者，利用一些算法实现P2P通信，缺点在于攻击者可以通过逆向分析其协议和特征，伪装为局域网管理者进行诱骗并分析所有受害主机；</li>
</ul>


<p>Botnet感染方式的进化流程如下：</p>

<ul>
<li>原始感染：通过受感染的机器去扫描更多的存在漏洞的主机并试图感染；</li>
<li>现有感染：（1）通过垃圾邮件发送恶意程序，（2）建立恶意网页，欺骗受害者浏览（drive-by-download attack）；</li>
</ul>


<h3>Botnet的检测研究</h3>

<p>针对Botnet的检测方式很多，概述如下：</p>

<ul>
<li>从主机层面进行检测：通过受害主机检测其样本，并提取特征码加入到杀毒软件特征库；通过分析恶意样本的语义和相似度进行匹配检测；基于动态进行的检测，其中还可以利用提取特征，机器学习进行结合；</li>
<li>从恶意网页进行检测：利用机器学习和页面的特征（重定向，混淆脚本代码）进行静态检测；可以通过虚拟机真实环境浏览网页来动态检测；另外也可以通过不同时间段页面的变化情况进行检测（黑客入侵后会添加恶意代码）；常用攻击代码片段或者内容进行分析判断；</li>
<li>从C&amp;C命令进行检测：通过透明协议，DGA域名进行检测；另外还可以通过搭建蜜罐抓取Botnet的行为进行分析；</li>
<li>从DNS协议进行检测：通过局域网DNS的异常或者不常见规律进行检测；</li>
<li>从SMTP协议进行检测：分析垃圾邮件的原始IP和其它信息来生成黑名单，或者统计这些IP规律；</li>
<li>从社交网络进行检测：攻击者利用社交网络来传播恶意软件，分析攻击者的社交行为给出其IP/域名的安全性；</li>
<li>从网络层面进行检测：恶意数据包，C&amp;C特定协议或者攻击包；</li>
</ul>


<h3>总结</h3>

<p>文章从Botnet的发展到进化，并针对不同的技术点总结了前人对该点的检测技术，整体而言，内容十分比较丰富，特别是参考文献。</p>
]]></content>
  </entry>
  
</feed>
